---
title: 操作系统
date: 2024-06-03 12:40:34
tags: CS笔记
categories: CS笔记
---

# 操作系统

> 参考哔哩哔哩的课程：<https://www.bilibili.com/video/BV1YB4y1i7xe/?spm_id_from=333.337.search-card.all.click&vd_source=731595967596af37618c926a191e7811>
>
> 参考了博客：<https://lfool.gitbook.io/operating-system/untitled-1/2.-cao-zuo-xi-tong-de-si-ge-te-zheng>
>
> 参考了大纲：<https://mubu.com/doc/d9TGd1--LY#m>
>
> 参考了图解系统：<https://xiaolincoding.com/os/1_hardware/how_cpu_run.html#%E5%9B%BE%E7%81%B5%E6%9C%BA%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F>
>
> 参考了视频：<https://www.bilibili.com/video/BV19r4y1b7Aw/?spm_id_from=333.337.search-card.all.click&vd_source=731595967596af37618c926a191e7811>
>
> 参考了：https://www.cnblogs.com/cxuanBlog/p/13320810.html

## 第一章 操作系统概述

### 操作系统的基本概念

操作系统是资源管理程序，其作用是控制管理计算机系统的资源和程序的指向。操作系统是计算机中最基础的软件，其作用简单来讲：

- 通过资源管理，提高计算机系统的**效率**

- 改善界面，为用户提供友好的工作环境（方便性）

![image-20240808153200733](06-03-操作系统/image-20240808153200733.png)

最开始的计算机是依靠图灵机而演变来的，通过图灵机可以较好的了解计算机发展的过程

#### 图灵机

图灵的基本思想是用机器来模拟人们用纸笔进行数学运算的过程，而且还定义了计算机由哪些部分组成，程序又是如何执行的。

![](06-03-操作系统/Turing%2Bmachine%2B1.jpeg)

图灵机的基本组成如下：

- 有一条「纸带」，纸带由一个个连续的格子组成，每个格子可以写入字符，纸带就好比内存，而纸带上的格子的字符就好比内存中的数据或程序；
- 有一个「读写头」，读写头可以读取纸带上任意格子的字符，也可以把字符写入到纸带的格子；
- 读写头上有一些部件，比如存储单元、控制单元以及运算单元： 1、存储单元用于存放数据； 2、控制单元用于识别字符是数据还是指令，以及控制程序的流程等； 3、运算单元用于执行运算指令

![img](06-03-操作系统/图灵机-第四步.png)

通过上面的图灵机计算 `1 + 2` 的过程，可以发现图灵机主要功能就是读取纸带格子中的内容，然后交给控制单元识别字符是数字还是运算符指令，如果是数字则存入到图灵机状态中，**如果是运算符，则通知运算符单元读取状态中的数值进行计算，计算结果最终返回给读写头，读写头把结果写入到纸带的格子中。**

#### 冯诺依曼架构

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1489371-20200205122018370-1525459707.png)

基本结构为 5 个部分，分别是**运算器、控制器、存储器、输入设备、输出设备**，包含这 5 个部分的计算机也被称为**冯诺依曼模型**。

**主机**：主机部分由运算器、存储器和控制器组成。

- **运算器**：负责执行所有的算术和逻辑运算。
- **存储器**：用于存储数据和指令。
- **控制器**：负责解释和执行指令，并控制其他部件的操作。

**外设**：由用户主导的输入和输出设备。

- **输入设备**：例如键盘、打孔卡片机等，用于将数据和指令输入到计算机中。
- **输出设备**：例如打印机、显示器等，用于将计算结果和其他信息输出给用户。

#### 程序执行的基本过程

程序实际上是一条一条指令，所以程序的运行过程就是把每一条指令一步一步的执行起来，负责执行指令的就是 CPU 了。

![img](06-03-操作系统/CPU执行程序.png)

 CPU 执行程序的过程如下：

- 第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。
- 第二步，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4；
- 第三步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行；

![CPU组成](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/689056-20211213001833220-675196650.png)

简单总结一下就是，一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 **CPU 的指令周期**。

#### [操作系统的分类](https://www.cnblogs.com/zhangqigao/p/7245342.html)

##### 无操作系统

1946年第一台计算机诞生--20世纪50年代中期，还未出现操作系统，计算机工作采用手工操作方式。

程序员将对应于程序和数据的已穿孔的纸带（或卡片）装入输入机，然后启动输入机把程序和数据输入计算机内存，接着通过控制台开关启动程序针对数据运行；计算完毕，打印机输出计算结果；用户取走结果并卸下纸带（或卡片）后，才让下一个用户上机。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/720333-20161209110618944-2068433671.png)

手工操作方式两个特点：

- 用户独占全机。不会出现因资源已被其他用户占用而等待的现象，但资源的利用率低。
- CPU 等待手工操作。CPU的利用不充分。

##### 批处理系统

批处理系统：加载在计算机上的一个系统软件，在它的控制下，计算机能够自动地、成批地处理一个或多个用户的作业（这作业包括程序、数据和命令）。

> **联机批处理系统**

首先出现的是联机批处理系统，即作业的输入/输出由CPU来处理。
主机与输入机之间增加一个存储设备——磁带，在运行于主机上的监督程序的自动控制下，计算机可自动完成：成批地把输入机上的用户作业读入磁带，依次把磁带上的用户作业读入主机内存并执行并把计算结果向输出机输出。完成了上一批作业后，监督程序又从输入机上输入另一批作业，保存在磁带上，并按上述步骤重复处理。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/720333-20161209111444304-2039311190.png)

监督程序不停地处理各个作业，从而实现了作业到作业的自动转接，减少了作业建立时间和手工操作时间，有效克服了人机矛盾，提高了计算机的利用率。

但是，在作业输入和结果输出时，主机的高速CPU仍处于空闲状态，等待慢速的输入/输出设备完成工作： 主机处于“忙等”状态。

> **脱机批处理系统**

为克服与缓解高速主机与慢速外设的矛盾，提高CPU的利用率，又引入了脱机批处理系统，即输入/输出脱离主机控制。
这种方式的显著特征是：增加一台不与主机直接相连而专门用于与输入/输出设备打交道的卫星机。

- 从输入机上读取用户作业并放到输入磁带上。
- 从输出磁带上读取执行结果并传给输出机。

这样，主机不是直接与慢速的输入/输出设备打交道，而是与速度相对较快的磁带机发生关系，有效缓解了主机与设备的矛盾。主机与卫星机可并行工作，二者分工明确，可以充分发挥主机的高速计算能力。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/720333-20161209111526460-204221213.png)

脱机批处理系统:20世纪60年代应用十分广泛，它极大缓解了人机矛盾及主机与外设的矛盾。IBM-7090/7094：配备的监督程序就是脱机批处理系统，是现代操作系统的原型。

**不足：每次主机内存中仅存放一道作业，每当它运行期间发出输入/输出（I/O）请求后，高速的CPU便处于等待低速的I/O完成状态，致使CPU空闲。**

为改善CPU的利用率，又引入了多道程序系统。

##### 多道处理系统

所谓多道程序设计技术，就是指允许多个程序同时进入内存并运行。即同时把多个程序放入内存，并允许它们交替在CPU中运行，它们共享系统中的各种硬、软件资源。当一道程序因I/O请求而暂停运行时，CPU便立即转去运行另一道程序。

> **单道程序的运行过程：**

在A程序计算时，I/O空闲， A程序I/O操作时，CPU空闲（B程序也是同样）；必须A工作完成后，B才能进入内存中开始工作，两者是串行的，全部完成共需时间=T1+T2。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/720333-20161209112227179-1811798925.png)

> **多道程序的运行过程：**

将A、B两道程序同时存放在内存中，它们在系统的控制下，可相互穿插、交替地在CPU上运行：当A程序因请求I/O操作而放弃CPU时，B程序就可占用CPU运行，这样 CPU不再空闲，而正进行A I/O操作的I/O设备也不空闲，显然，CPU和I/O设备都处于“忙”状态，大大提高了资源的利用率，从而也提高了系统的效率，A、B全部完成所需时间<<T1+T2。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/720333-20161209112543913-803992903.png)

多道程序设计技术不仅使CPU得到充分利用，同时改善I/O设备和内存的利用率，从而提高了整个系统的资源利用率和系统吞吐量（单位时间内处理作业（程序）的个数），最终提高了整个系统的效率。

单处理机系统中多道程序运行时的特点：

- 多道：计算机内存中同时存放几道相互独立的程序；
- 宏观上并行：同时进入系统的几道程序都处于运行过程中，即它们先后开始了各自的运行，但都未运行完毕；
- 微观上串行：实际上，各道程序轮流地用CPU，并交替运行。

多道程序系统的出现，标志着操作系统渐趋成熟的阶段，先后出现了作业调度管理、处理机管理、存储器管理、外部设备管理、文件系统管理等功能。

> **多道批处理系统**

20世纪60年代中期，在前述的批处理系统中，引入多道程序设计技术后形成多道批处理系统（简称：批处理系统）。它有两个特点：

- 多道：系统内可同时容纳多个作业。这些作业放在外存中，组成一个后备队列，系统按一定的调度原则每次从后备作业队列中选取一个或多个作业进入内存运行，运行作业结束、退出运行和后备作业进入运行均由系统自动实现，从而在系统中形成一个自动转接的、连续的作业流。
- 成批：在系统运行过程中，不允许用户与其作业发生交互作用，即：作业一旦进入系统，用户就不能直接干预其作业的运行。

批处理系统的追求目标：提高系统资源利用率和系统吞吐量，以及作业流程的自动化。

*批处理系统的一个重要缺点：不提供人机交互能力，给用户使用计算机带来不便。
虽然用户独占全机资源，并且直接控制程序的运行，可以随时了解程序运行情况。但这种工作方式因独占全机造成资源效率极低。*

一种新的追求目标：既能保证计算机效率，又能方便用户使用计算机。 20世纪60年代中期，计算机技术和软件技术的发展使这种追求成为可能。

##### 分时操作系统

由于CPU速度不断提高和采用分时技术，一台计算机可同时连接多个用户终端，而每个用户可在自己的终端上联机使用计算机，好象自己独占机器一样。

分时技术：**把处理机的运行时间分成很短的时间片，按时间片轮流把处理机分配给各联机作业使用。**

若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时中断，把处理机让给另一作业使用，等待下一轮时再继续其运行。由于计算机速度很快，作业运行轮转得很快，给每个用户的印象是，好象他独占了一台计算机。而每个用户可以通过自己的终端向系统发出各种操作控制命令，在充分的人机交互情况下，完成作业的运行。

具有上述特征的计算机系统称为分时系统，它允许多个用户同时联机使用计算机。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/720333-20161209115854288-2114494926.png)

- 多路性。若干个用户同时使用一台计算机。微观上看是各用户轮流使用计算机；宏观上看是各用户并行工作。
- 交互性。用户可根据系统对请求的响应结果，进一步向系统提出新的请求。这种能使用户与系统进行人机对话的工作方式，明显地有别于批处理系统，因而，分时系统又被称为交互式系统。
- 独立性。用户之间可以相互独立操作，互不干扰。系统保证各用户程序运行的完整性，不会发生相互混淆或破坏现象。
- 及时性。系统可对用户的输入及时作出响应。分时系统性能的主要指标之一是响应时间，它是指：从终端发出命令到系统予以应答所需的时间。


分时系统的主要目标：对用户响应的及时性，即不至于用户等待每一个命令的处理时间过长。

分时系统可以同时接纳数十个甚至上百个用户，由于内存空间有限，往往采用对换（又称交换）方式的存储方法。即将未“轮到”的作业放入磁盘，一旦“轮到”，再将其调入内存；而时间片用完后，又将作业存回磁盘（俗称“滚进”、“滚出“法），使同一存储区域轮流为多个用户服务。

**多用户分时系统是当今计算机操作系统中最普遍使用的一类操作系统。**

##### 实时系统

虽然多道批处理系统和分时系统能获得较令人满意的资源利用率和系统响应时间，但却不能满足实时控制与实时信息处理两个应用领域的需求。于是就产生了实时系统，即系统能够及时响应随机发生的外部事件，并在严格的时间范围内完成对该事件的处理。实时系统在一个特定的应用中常作为一种控制设备来使用。

实时系统可分成两类：

- 实时控制系统。当用于飞机飞行、导弹发射等的自动控制时，要求计算机能尽快处理测量系统测得的数据，及时地对飞机或导弹进行控制，或将有关信息通过显示终端提供给决策人员。当用于轧钢、石化等工业生产过程控制时，也要求计算机能及时处理由各类传感器送来的数据，然后控制相应的执行机构。
- 实时信息处理系统。当用于预定飞机票、查询有关航班、航线、票价等事宜时，或当用于银行系统、情报检索系统时，都要求计算机能对终端设备发来的服务请求及时予以正确的回答。此类对响应及时性的要求稍弱于第一类。


实时操作系统的主要特点：

- 及时响应。每一个信息接收、分析处理和发送的过程必须在严格的时间限制内完成。
- 高可靠性。需采取冗余措施，双机系统前后台工作，也包括必要的保密措施等。

> 操作系统发展图谱

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/720333-20161209122423397-353003684.png)

### 操作系统运行环境*

![冷月手撕408之操作系统(4)-操作系统的运行环境_操作系统](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/resize,m_fixed,w_1184.webp)

在计算机中存在两种程序，系统外层的**应用程序**和**内核程序**。CPU在设计时存在**特权指令**与**非特权指令**，特权指令例如内存指令等。

#### 处理器执行状态*

**内核态和用户态是操作系统中的两种运行模式。**它们的主要区别在于权限和可执行的操作：

- 内核态（Kernel Mode）：在内核态下，CPU可以执行所有的指令和访问所有的硬件资源。这种模式下的操作具有更高的权限，主要用于操作系统内核的运行。
- 用户态（User Mode）：在用户态下，CPU只能执行部分指令集，无法直接访问硬件资源。这种模式下的操作权限较低，主要用于运行用户程序。

**内核态的底层操作主要包括：内存管理、进程管理、设备驱动程序控制、系统调用等。**这些操作涉及到操作系统的核心功能，需要较高的权限来执行。

分为内核态和用户态的原因主要有以下几点：

- 安全性：通过对权限的划分，用户程序无法直接访问硬件资源，从而避免了恶意程序对系统资源的破坏。
- 稳定性：用户态程序出现问题时，不会影响到整个系统，避免了程序故障导致系统崩溃的风险。
- 隔离性：内核态和用户态的划分使得操作系统内核与用户程序之间有了明确的边界，有利于系统的模块化和维护。

##### 内核态(特权模式)

**内核态也被称为内核模式或特权模式，是操作系统内核的运行状态。**处于内核态的CPU可以执行所有的指令，访问所有的内存地址，拥有最高的权限。**内核态下运行的程序可以访问系统的所有资源，包括CPU、内存、I/O等。**

在内核态下，操作系统可以响应所有的中断请求，处理硬件事件和系统调用。当应用程序发出系统调用时，CPU会切换到内核态，执行相应的操作，然后返回用户态。此外，当发生严重错误或异常时，也会触发内核态的切换。

##### 用户态(用户模式)

**用户态也被称为用户模式，是指应用程序的运行状态。**在这种模式下，应用程序拥有有限的系统资源访问权限，只能在操作系统划定的特定空间内运行。**用户态下运行的程序不能直接访问硬件设备或执行特权指令，所有对硬件的访问都必须通过操作系统进行。**

在用户态下，应用程序通过系统调用来请求操作系统提供的服务。例如，文件操作、网络通信等都需要通过系统调用来实现。当应用程序发出系统调用时，会触发上下文切换，将CPU的控制权交给操作系统内核，进入内核态。

#### 内核指令

##### 时钟管理

时钟在操作系统中扮演着非常关键的角色，其主要功能和用途包括：

**计时**：时钟提供了系统时间的基准，允许操作系统跟踪时间和日期。这是许多系统功能（如文件时间戳、计划任务）所必需的。

**时钟中断**：时钟中断是操作系统用于时间管理的核心机制。通过定期触发时钟中断，操作系统可以执行以下任务：

- **进程切换**：在多任务操作系统中，时钟中断用于进程调度。调度程序可以决定是否需要进行上下文切换，以确保各个进程按计划运行。
- **时间片管理**：操作系统通过时钟中断来实现时间片轮转调度（Round-Robin Scheduling），确保每个进程在特定的时间片内执行。时间片结束时，时钟中断触发，调度程序检查是否需要将CPU分配给其他进程。

##### 中断机制

中断机制是操作系统响应各种事件的基本机制，分为硬件中断和软件中断。

**硬件中断**：来自外部设备的信号，通知CPU有事件需要处理，例如：

- **键盘输入**：用户按键产生中断，操作系统读取输入数据。
- **网络数据包**：网络接口卡接收到数据包，产生中断通知操作系统处理。
- **定时器中断**：系统时钟定期产生中断，用于维护时间和调度。

**软件中断**：由程序或操作系统生成的中断，通常用于系统调用和异常处理，例如：

- **系统调用**：用户程序通过软件中断请求操作系统服务。
- **异常处理**：例如除零错误、非法访问内存等会产生软件中断，操作系统捕获并处理这些异常。

##### 原语

原语（primitive）是操作系统提供的基本操作，通常是底层的、不可分割的操作，具有以下特点

- **接近硬件**：原语通常直接操作硬件或系统的核心数据结构，如进程控制块、内存页表等。
- **原子性**：原语必须是原子操作，确保操作在执行过程中不被中断，以保持系统的一致性和稳定性。例如，禁用中断期间的上下文切换操作。
- **运行时间短**：原语通常设计为非常短小，以减少对系统的整体性能影响。它们被频繁调用，必须执行迅速，以确保操作系统的高效性。

### 中断与异常

中断是计算机系统中用于响应硬件设备请求的一种机制。用一个生活中的例子来形象地解释：小林中午搬完砖后点了一份外卖，但他不会一直盯着手机等外卖送达，而是去干别的事情。当外卖员打电话通知他时，小林会停下手中的工作去取外卖。**在这个例子中，电话通知就相当于计算机中的中断。**外卖送达前，小林可以做其他事情（计算机在等待中断时处理其他任务）。**一旦电话响起（中断发生），小林就会停止当前任务去应对（处理中断）。**

中断是一种**异步事件处理机制**，提高了系统的并发处理能力。操作系统收到中断请求后，会暂停当前进程，调用中断处理程序来响应请求。**中断处理程序应尽快完成，以免影响其他进程或中断请求的处理，就像小林希望电话通话时间越短越好，避免占用太久影响其他来电。**

#### **中断（外中断）**

中断是系统正常操作的一部分，用于响应外部事件。

- **外设请求**：例如，输入设备、网络适配器发出的信号。
- **人的干预**：如键盘中断或用户请求。

![image-20240622192715954](06-03-操作系统/image-20240622192715954.png)

#### **异常（内中断）**

异常是指在程序执行过程中出现的错误或非正常情况。例如，除以零、访问不存在的内存地址等等。当发生异常时，操作系统会停止当前进程的执行，并处理异常。处理完毕后，操作系统会终止当前进程并回收资源。

- **文件损坏**：例如，尝试访问受损的文件。
- **进程越界**：如访问非法内存地址。
- **算术溢出**：例如，整数溢出或除零错误。
- **硬件故障**：如硬件组件出现故障。
- **软件中断**：程序故意触发的软件中断请求。

异常通常是不预期的，指示系统出现了错误或问题。

**区别**：异常是中断的一种特殊形式，主要由于错误或不正常的情况触发，而中断不一定是由异常引起的，它可以是外部设备的正常请求或用户操作。

#### 中断处理过程

1. **关闭中断**：为了防止在处理中断时发生新的中断，系统会首先禁用中断。
2. **保存断点**：保存当前的程序计数器（PC）和其他执行状态，以便在中断处理完成后能够恢复到中断发生前的状态。
3. **中断服务程序寻址**：根据中断向量表，确定需要执行的中断服务程序（Interrupt Service Routine, ISR）。
4. **保存现场和屏蔽字**：保存当前寄存器内容和其他重要状态信息，同时设置中断屏蔽，以防止中断处理过程中被其他中断打断。
5. **重新开启中断**：启用中断，使系统能够在处理过程中响应新的中断请求。这可以提高系统的响应能力。
6. **执行中断服务程序**：执行相应的中断服务程序，处理具体的中断请求，如读取设备数据、更新系统状态等。
7. **关闭中断**：在恢复之前，暂时关闭中断，确保恢复现场时不被新的中断打断。
8. **恢复现场和屏蔽字**：恢复先前保存的寄存器和状态信息，以及中断屏蔽状态，确保系统能够恢复到中断前的状态。
9. **开启中断并返回**：重新启用中断，并将控制权返回给中断发生之前的程序，继续执行被中断的任务。

- **步骤 1~3**：由硬件（如CPU和中断控制器）自动完成。这些步骤负责检测中断并做好进入中断处理的准备。
- **步骤 4~9**：由中断处理程序（软件）完成。这些步骤确保系统在处理中断请求后，能够正确恢复并继续执行。

### [操作系统的体系结构*](https://www.cnblogs.com/cherish-/p/15755441.html)

#### 单体结构

到目前为止，在大多数系统中，整个系统在内核态以单一程序的方式运行。整个操作系统是以程序集合来编写的，链接在一块形成一个大的二进制可执行程序。使用此技术时，如果系统中的每个过程都提供了前者所需的一些有用的计算，则它可以自由调用任何其他过程。在单体系统中，调用任何一个所需要的程序都非常高效，但是上千个不受限制的彼此调用往往非常臃肿和笨拙，而且单体系统必然存在单体问题，那就是只要系统发生故障，那么任何系统和应用程序将不可用，这往往是灾难性的。

在单体系统中构造实际目标程序时，会首先编译所有单个过程（或包含这些过程的文件），然后使用系统链接器将它们全部绑定到一个可执行文件中

对于单体系统，往往有下面几种建议

- 需要有一个主程序，用来调用请求服务程序
- 需要一套服务过程，用来执行系统调用
- 需要一套服务程序，用来辅助服务过程调用

在单体系统中，对于每个系统调用都会有一个服务程序来保障和运行。需要一组实用程序来弥补服务程序需要的功能，例如从用户程序中获取数据。可将各种过程划分为一个三层模型

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200228112223032-1415953134.png)

除了在计算机初启动时所装载的核心操作系统外，许多操作系统还支持额外的扩展。比如 I/O 设备驱动和文件系统。这些部件可以按需装载。在 UNIX 中把它们叫做 `共享库(shared library)`，在 Windows 中则被称为 `动态链接库(Dynamic Link Library,DLL)`。他们的扩展名为 `.dll`，在 `C:\Windows\system32` 目录下存在 1000 多个 DLL 文件，所以不要轻易删除 C 盘文件，否则可能就炸了哦。

#### 层次结构

分层系统使用层来分隔不同的功能单元。每一层只与该层的上层和下层通信。每一层都使用下面的层来执行其功能。层之间的通信通过预定义的固定接口通信。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200228112231677-181981184.png)

分层系统是由 `E.W.Dijkstar` 和他的学生在荷兰技术学院所开发的 THE 系统。

把上面单体系统进一步通用化，就变为了一个层次式结构的操作系统，它的上层软件都是在下层软件的基础之上构建的。该系统分为六层，如下所示

| 层号 | 功能                     |
| ---- | ------------------------ |
| 5    | 操作员                   |
| 4    | 用户程序                 |
| 3    | 输入/输出管理            |
| 2    | 操作员-进程通信          |
| 1    | 存储器和磁鼓管理         |
| 0    | 处理器分配和多道程序编程 |

处理器在 0 层运行，当中断发生或定时器到期时，由该层完成进程切换；在第 0 层之上，系统由一些连续的进程组成，编写这些进程时不用再考虑在单处理器上多进程运行的细节。内存管理在第 1 层，它分配进程的主存空间。第 1 层软件保证一旦需要访问某一页面，该页面必定已经在内存中，并且在页面不需要的时候将其移出。

第 2 层处理进程与操作员控制台（即用户）之间的通信。第 3 层管理 I/O 设备和相关的信息流缓冲区。第 4 层是用户程序层，用户程序不用考虑进程、内存、控制台或 I/O 设备管理等细节。系统操作员在第 5 层。

#### 微内核结构

在分层方式中，设计者要确定在哪里划分 `内核-用户` 的边界。传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能可能是更好的做法。因为内核中的错误很难处理，一旦内核态中出错误会拖累整个系统。

所以，为了实现高可靠性，将操作系统划分成小的、层级之间能够更好定义的模块是很有必要的，只有一个模块 --- 微内核 --- 运行在内核态，其余模块可以作为普通用户进程运行。由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使整个系统死机。

`MINIX 3` 是微内核的代表作，它的具体结构如下

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200228112247719-997139588.png)

在内核的外部，系统的构造有三层，它们都在用户态下运行，最底层是设备驱动器。由于它们都在用户态下运行，所以不能物理的访问 I/O 端口空间，也不能直接发出 I/O 命令。相反，为了能够对 I/O 设备编程，驱动器构建一个结构，指明哪个参数值写到哪个 I/O 端口，并声称一个内核调用，这样就完成了一次调用过程。

位于用户态的驱动程序上面是`服务器`层，包含有服务器，它们完成操作系统的多数工作。由一个或多个文件服务器管理着文件系统，进程管理器创建、销毁和管理进程。服务器中有一个特殊的服务器称为 `再生服务器(reincarnation server)`，它的任务就是检查服务器和驱动程序的功能是否正确，一旦检查出来错误，它就会补上去，无需用户干预。这种方式使得系统具有可恢复性，并具有较高的可靠性。

微内核中的内核还具有一种 `机制` 与 `策略` 分离的思想。比如系统调度，一个比较简单的调度算法是，对每个进程赋予一个优先级，并让内核执行具有最高优先级的进程。这里，内核机制就是寻找最高的优先级进程并运行。而策略（赋予进程优先级）可以在用户态中的进程完成。在这种模式中，策略和机制是分离的，从而使内核变得更小。

#### 客户-服务器模式

微内核思想的策略是把进程划分为两类：`服务器`，每个服务器用来提供服务；`客户端`，使用这些服务。这个模式就是所谓的 `客户-服务器`模式。

客户-服务器模式会有两种载体，一种情况是一台计算机既是客户又是服务器，在这种方式下，操作系统会有某种优化；但是普遍情况下是客户端和服务器在不同的机器上，它们通过局域网或广域网连接。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200228112305395-673145012.png)

客户通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。

越来越多的系统，包括家里的 PC，都成为客户端，而在某地运行的大型机器则成为服务器。许多 web 就是以这种方式运行的。一台 PC 向某个服务器请求一个 Web 页面，服务器把 Web 页面返回给客户端，这就是典型的客服-服务器模式

### 组成硬件

#### 内存(RAM)

在计算机数据存储中，存储数据的基本单位是**字节（\*byte\*）**，1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。

内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1，这种结构好似我们程序里的数组，所以内存的读写任何一个数据的速度都是一样的。

#### 中央处理器(CPU)

CPU的作用是取值执行，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据：

- 32 位 CPU 一次可以计算 4 个字节；
- 64 位 CPU 一次可以计算 8 个字节；

之所以 CPU 要这样设计，是为了能计算更大的数值，如果是 8 位的 CPU，那么一次只能计算 1 个字节 `0~255` 范围内的数值，这样就无法一次完成计算 `10000 * 500` ，于是为了能一次计算大数的运算，CPU 需要支持多个 byte 一起计算，所以 CPU 位宽越大，可以计算的数值就越大，比如说 32 位 CPU 能计算的最大整数是 `4294967295`。

**[寄存器](https://www.cnblogs.com/FengZeng666/p/15711562.html)**

- **程序计数器（PC，Program counter），用于存放指令的地址。**为了保证程序(在操作系统中理解为进程)能够连续地执行下去，CPU必须具有某些手段来确定下一条指令的地址。当执行一条指令时，首先需要根据PC中存放的指令地址，将指令由内存取到指令寄存器中，此过程称，为“取指令”。与此同时，PC中的地址或自动加1或由转移指针给出下一条指令的地址。此后经过分析指令，执行指令。完成第一条指令的执行，而后根据PC取出第二条指令的地址，如此循环，执行每一条指令。

- **指令寄存器（IR，Instruction Register），用来保存当前正在执行的一条指令。**是临时放置从内存里面取得的程序指令的寄存器，用于存放当前从主存储器读出的正在执行的一条指令。当执行一条指令时，先把它从内存取到数据寄存器（DR，Data Register）中，然后再传送至IR。指令划分为操作码和地址码字段，由二进制数字组成。为了执行任何给定的指令，必须对操作码进行测试，以便识别所要求的操作。指令译码器就是做这项工作的。指令寄存器中操作码字段的输出就是指令译码器的输入。操作码一经译码后，即可向操作控制器发出具体操作的特定信号。

- **通用寄存器（GR，General register）：通用寄存器可用于传送和暂存数据，也可参与算术逻辑运算，并保存运算结果。**除此之外，它们还各自具有一些特殊功能。通用寄存器的长度取决于机器字长，汇编语言程序员必须熟悉每个寄存器的一般用途和特殊用途，只有这样，才能在程序中做到正确、合理地使用它们。

#### 总线

总线是用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：

- *地址总线*，用于指定 CPU 将要操作的内存地址；
- *数据总线*，用于读写内存的数据；
- *控制总线*，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；

当 CPU 要读写内存数据的时候，一般需要通过下面这三个总线：

- 首先要通过「地址总线」来指定内存的地址；
- 然后通过「控制总线」控制是读或写命令；
- 最后通过「数据总线」来传输数据；

## 第二章 进程与线程

### 进程*

操作系统中最核心的概念就是 `进程`，**进程是对正在运行中的程序的一个抽象**。操作系统的其他所有内容都是围绕着进程展开的。进程是操作系统提供的最古老也是最重要的概念之一。即使可以使用的 CPU 只有一个，**它们也支持`（伪）并发`操作**。它们会将一个**单独的 CPU 抽象为多个虚拟机的 CPU**。可以说：没有进程的抽象，现代操作系统将不复存在。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303145537544-1636071982.png)

所有现代的计算机会在同一时刻做很多事情，过去使用计算机的人（单 CPU）可能完全无法理解现在这种变化，举个例子更能说明这一点：首先考虑一个 Web 服务器，请求都来自于 Web 网页。**当一个请求到达时，服务器会检查当前页是否在缓存中，如果是在缓存中，就直接把缓存中的内容返回。**如果缓存中没有的话，那么请求就会交给磁盘来处理。但是，从 CPU 的角度来看，磁盘请求需要更长的时间，因为磁盘请求会很慢。当硬盘请求完成时，更多其他请求才会进入。如果有多个磁盘的话，可以在第一个请求完成前就可以连续的对其他磁盘发出部分或全部请求。很显然，这是一种并发现象，需要有并发控制条件来控制并发现象。

现在考虑只有一个用户的 PC。当系统启动时，许多进程也在后台启动，用户通常不知道这些进程的启动，试想一下，当你自己的计算机启动的时候，你能知道哪些进程是需要启动的么？这些后台进程可能是一个需要输入电子邮件的电子邮件进程，或者是一个计算机病毒查杀进程来周期性的更新病毒库。某个用户进程可能会在所有用户上网的时候打印文件以及刻录 CD-ROM，这些活动都需要管理。**于是一个支持多进程的多道程序系统就会显得很有必要了。**

在许多多道程序系统中，**CPU 会在`进程`间快速切换，使每个程序运行几十或者几百毫秒。然而，严格意义来说，在某一个瞬间，CPU 只能运行一个进程，然而我们如果把时间定位为 1 秒内的话，它可能运行多个进程。这样就会让我们产生`并行`的错觉。**有时候人们说的 `伪并行(pseudoparallelism)` 就是这种情况，以此来区分多处理器系统**(该系统由两个或多个 CPU 来共享同一个物理内存)**

> 再来详细解释一下伪并行：`伪并行`是指单核或多核处理器同时执行多个进程，从而使程序更快。 通过以非常有限的时间间隔在程序之间快速切换CPU，因此会产生并行感。 缺点是 CPU 时间可能分配给下一个进程，也可能不分配给下一个进程。

因为 CPU 执行速度很快，进程间的换进换出也非常迅速，因此我们很难对多个并行进程进行跟踪，所以，在经过多年的努力后，操作系统的设计者开发了用于描述并行的一种概念模型（顺序进程），使得并行更加容易理解和分析。

#### 进程模型

在进程模型中，所有计算机上运行的软件，通常也包括操作系统，被组织为若干**`顺序进程(sequential processes)`**，简称为 `进程(process)` 。一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换。

> 这种方式不是主流，主流的是抢占式多任务

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303145547712-749055376.png)

如上图所示，这是一个具有 4 个程序的多道处理程序，在进程不断切换的过程中，**程序计数器也在不同的变化。**

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303145556495-448263493.png)

在上图中，这 4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个**程序都独立的运行**。当然，实际上只有一个物理程序计数器，**每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。**当程序运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。

从下图我们可以看到，在观察足够长的一段时间后，所有的进程都运行了，**但在任何一个给定的瞬间仅有一个进程真正运行**。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303145604741-151453806.png)

因此，当我们说一个 CPU 只能真正一次运行一个进程的时候，即使有 2 个核（或 CPU），**每一个核也只能一次运行一个线程**。

由于 **CPU 会在各个进程之间来回快速切换**，所以每个进程在 CPU 中的运行时间是无法确定的。并且当同一个进程再次在 CPU 中运行时，其在 CPU 内部的运行时间往往也是不固定的。进程和程序之间的区别是非常微妙的，但是通过一个例子可以让你加以区分：想想一位会做饭的计算机科学家正在为他的女儿制作生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原料：面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序、计算机科学家就是 CPU、**而做蛋糕的各种原料都是输入数据。**进程就是科学家阅读食谱、取来各种原料以及烘焙蛋糕等一系例了动作的总和。

现在假设科学家的儿子跑过来告诉他，说他的头被蜜蜂蜇了一下，那么此时科学家会记录出来他做蛋糕这个过程到了哪一步，然后拿出急救手册，按照上面的步骤给他儿子实施救助。这里，会涉及到进程之间的切换，科学家（CPU）会从做蛋糕（进程）切换到实施医疗救助（另一个进程）。**等待伤口处理完毕后，科学家会回到刚刚记录做蛋糕的那一步，继续制作。**

这里的关键思想是`认识到一个进程所需的条件`，进程是某一类特定活动的总和，**它有程序、输入输出以及状态。**单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另外一个进程提供服务。另外需要注意的是，**如果一个进程运行了两遍，则被认为是两个进程。**那么我们了解到进程模型后，那么进程是如何创建的呢？

> 针对于上述特点总结了一下性质

**进程的特征**：

- **动态性**：进程是程序的执行过程，动态产生、变化和消亡。
- **并发性**：多个进程可同时执行。
- **独立性**：进程能独立运行、获取资源和接受调度。
- **异步性**：进程按各自速度执行，需操作系统提供同步机制。
- **结构性**：每个进程有一个进程控制块（PCB），包含程序段和数据段。

（程序段:是指程序的代码，数据段:是指运行过程中产生的各种数据）

#### 进程的终止

进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的

- `正常退出(自愿的)`
- `错误退出(自愿的)`
- `严重错误(非自愿的)`
- `被其他进程杀死(非自愿的)`

1. 正常退出

   多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 `exit` ，在 Windows 中是 `ExitProcess`。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的**程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它锁打开的任何临时文件，然后终止。**

2. 错误退出

   进程发生终止的第二个原因是发现严重错误，例如，如果用户执行如下命令`cc foo.c	`

   为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候**应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。**

3. 严重错误

   进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所导致的。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。

4. 被其他进程杀死

   第四个终止进程的原因是，**某个进程执行系统调用告诉操作系统杀死某个进程。**在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 `TerminateProcess`（注意不是系统调用）。

#### 进程控制块(PCB)

**PCB 是进程存在的唯一标识**，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。

![image-20240622194634874](06-03-操作系统/image-20240622194634874.png)

PCB具体包含的信息如下：

1. 进程描述信息
   - 进程标识符：标识各个进程，每个进程都有一个并且**唯一的标识符(PID)**
   - 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务


2. 进程控制和管理信息：
   - 进程当前状态，如 new、ready、running、waiting 或 blocked 等
   - 进程优先级：进程抢占 CPU 时的优先级


3. 资源分配清单：
   - 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所**使用的 I/O 设备信息。**


4. CPU 相关信息：
   - CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。


可见，PCB 包含信息还是比较多的。每个 PCB 是如何组织的呢？通常是通过**链表**的方式进行组织，把**具有相同状态的进程链在一起，组成各种队列。**比如：

- 将所有处于就绪状态的进程链在一起，称为**就绪队列**；
- 把所有因等待某事件而处于等待状态的进程链在一起就组成各种**阻塞队列**；
- 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。

![就绪队列和阻塞队列](06-03-操作系统/12-PCB状态链表组织.jpg)

除了链接的组织方式，还有索引方式，**它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。**一般会选择链表，是因为可能面临进程创建，销毁等调度导致进程状态发生变化，通过链表能够更加灵活的插入和删除。

#### 进程状态

一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。

所以，**在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。**

![进程的三种基本状态](06-03-操作系统/7-进程三个基本状态.jpg)

上图中各个状态的意义：

- 运行状态（*Running*）：该时刻进程占用 CPU；
- 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；
- 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

当然，进程还有另外两个基本状态：

- 创建状态（*new*）：进程正在被创建时的状态；
- 结束状态（*Exit*）：进程正在从系统中消失时的状态；

于是，一个完整的进程状态的变迁如下图：

![进程五种状态的变迁](06-03-操作系统/8-进程五个状态.jpg)

再来详细说明一下进程的状态变迁：

- **NULL -> 创建状态**：一个新进程被创建时的第一个状态。

- **创建状态 -> 就绪状态**：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的。
  - **过程**：申请空白PCB → 填写控制信息 → 分配资源 → 转入就绪状态（若资源足够）。

- **就绪状态 -> 运行状态**：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程。

  - **特征**：在就绪队列中等待调度。

  - **原因**：进程被调度程序选中，获得CPU时间片。

- **运行状态 -> 结束状态**：当进程已经运行完成或出错时，会被操作系统作结束状态处理。
  - **描述**：进程正在使用CPU执行任务。

- **运行状态 -> 就绪状态**：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行。
  - **原因**：时间片用完，或有更高优先级的进程变为就绪状态。

- **运行状态 -> 阻塞状态**：当进程请求某个事件且必须等待时，例如请求 I/O 事件。

  - **描述**：进程等待某些事件发生，如I/O操作完成或资源释放。

  - **原因**：进程因等待某些事件（如I/O操作）而无法继续执行。

- **阻塞状态 -> 就绪状态**：当进程要等待的事件完成时，它从阻塞状态变到就绪状态。
  - **原因**：所等待的事件发生，进程被唤醒，重新进入就绪队列。

- **结束状态**：
  - **描述**：进程正常或异常结束，操作系统进行善后处理，清除PCB并释放资源
  

如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。**所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。**

![虚拟内存管理-换入换出](06-03-操作系统/9-换入换出.jpg)

那么，就需要一个新的状态，来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。

另外，挂起状态可以分为两种：

- **阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现**
- **就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行**

这两种挂起状态加上前面的五种状态，就变成了七种状态变迁

![七种状态变迁](06-03-操作系统/10-进程七中状态.jpg)

导致进程**挂起的原因**不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：

- 通过 sleep 让进程间歇性挂起，其工作原理是**设置一个定时器**，到期后唤醒进程。
- 用户希望挂起一个程序的执行，比如在 Linux 中用 `Ctrl+Z` 挂起进程

##### 进程控制

我们熟知了**进程的状态变迁和进程的数据结构 PCB** 后，再来看看进程的**创建、终止、阻塞、唤醒**的过程，这些过程也就是进程的控制。

1. 创建进程

   操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。创建进程的过程如下：

   - 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；

   - 为该进程分配运行时所必需的资源，比如内存资源；

   - 将 PCB 插入到就绪队列，等待被调度运行；


2. 终止进程进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 `kill` 掉）。

   **当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。**终止进程的过程如下：

   - 查找需要终止的进程的 PCB；

   - 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；

   - 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；

   - 将该进程所拥有的全部资源都归还给操作系统；

   - 将其从 PCB 所在队列中删除；


3. 阻塞进程

   当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。阻塞进程的过程如下：

   - 找到将要被阻塞进程标识号对应的 PCB

   - 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行

   - 将该 PCB 插入到阻塞队列中去


4. 唤醒进程

   **进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成**，所以处于阻塞状态的进程是绝对不可能叫醒自己的。如果某进程正在等待 I/O 事件，**需由别的进程发消息给它**，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。唤醒进程的过程如下：

   - 在该事件的**阻塞队列中找到相应进程的 PCB**

   - 将其从阻塞队列中移出，并置其状态为就绪状态

   - 把该 PCB 插入到就绪队列中，等待调度程序调度


进程的阻塞和唤醒是一对功能相反的语句，如果**某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。**

##### 上下文切换

**进程切换到另一个进程运行，称为进程的上下文切换**。

> 在详细说进程上下文切换前，先来看看 CPU 上下文切换

大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。

所以，操作系统需要事先帮 CPU 设置好 **CPU 寄存器和程序计数器**。

**CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。**举个例子，寄存器像是你的口袋，内存像你的书包，硬盘则是你家里的柜子，如果你的东西存放到口袋，那肯定是比你从书包或家里柜子取出来要快的多。

再来，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。所以说，**CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。**既然知道了什么是 CPU 上下文，那理解 CPU 上下文切换就不难了。

CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

**系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响**，让任务看起来还是连续运行。上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：**进程上下文切换、线程上下文切换和中断上下文切换**。

> 进程的上下文切换到底是切换什么

进程是由内核管理和调度的，所以进程的切换只能发生在内核态。

所以，**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：

![进程上下文切换](06-03-操作系统/13-进程上下文切换.jpg)

**需要注意的是，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。**

> 发生进程上下文切换的哪些场景

- 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；
- 进程在系统资源不足（比如内存不足）时，**要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行**
- 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；

### 线程*

#### 线程简述

在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面，计算机科学家们又提出了更小的能独立运行的基本单位，也就是**线程。**

> 可以把线程理解为轻量级进程或者理解为在CPU中运行的最小程序

我们举个例子，假设你要编写一个视频播放器软件，那么该软件功能的核心模块有三个

- 从视频文件当中读取数据；
- 对读取的数据进行解压缩；
- 把解压缩后的视频数据播放出来；

对于单进程的实现方式，会是以下这个方式：

![单进程实现方式](06-03-操作系统/14-单线程mp4代码实例.jpg)

对于单进程的这种方式，存在以下问题：

- 播放出来的画面和声音会不连贯，因为当 CPU 能力不够强的时候，**`Read` 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放；**
- 各个函数之间不是并发执行，影响资源的使用效率

改进成多进程的方式：

![多进程实现方式](06-03-操作系统/15-多进程mp4-代码实例.jpg)

对于多进程的这种方式，依然会存在问题：

- 进程之间如何通信，共享数据？比如我需要根据不同的视频进度更新进度条，但是进程之间无法直接通讯，速度就很慢。
- **同时维护进程的系统开销较大**，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息；

为了解决这些问题需要有一种新的实体，满足以下特性：

- **实体之间可以并发运行**
- **实体之间共享相同的地址空间**

这个时候就发明出了线程，通常我们说的多线程是存在于一个进程中的。但是为什么要在进程的基础上再创建一个线程的概念，准确的说，这其实是进程模型和线程模型的讨论，回答这个问题，可能需要分三步来回答

- 多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的
- 线程要比进程`更轻量级`，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。
- 第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度

通过线程，我们就可以解决上面提出的问题。

#### 线程模型

理解进程的另一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。**这些资源包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把这些信息放在进程中会比较容易管理。**

另一个概念是，**进程中拥有一个执行的线程**，通常简写为 `线程(thread)`。线程会有程序计数器，用来记录接着要执行哪一条指令；**线程还拥有寄存器**，用来保存线程当前正在使用的变量；线程还会有堆栈，用来记录程序的执行路径。尽管线程必须在某个进程中执行，但是进程和线程完完全全是两个不同的概念，并且他们可以分开处理。**进程用于把资源集中在一起，而线程则是 CPU 上调度执行的实体。**

线程给进程模型增加了一项内容，即在同一个进程中，允许彼此之间有较大的独立性且互不干扰。在**一个进程中并行运行多个线程类似于在一台计算机上运行多个进程**。在多个线程中，各个线程共享同一地址空间和其他资源。在多个进程中，进程共享物理内存、磁盘、打印机和其他资源。因为线程会包含有一些进程的属性，所以线程被称为`轻量的进程(lightweight processes)`。**`多线程(multithreading)`一词还用于描述在同一进程中多个线程的情况。**

下图我们可以看到三个传统的进程，每个进程有自己的地址空间和单个控制线程。**每个线程都在不同的地址空间中运行**

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303150125472-1729710870.png)

下图中，我们可以看到有一个进程三个线程的情况。每个线程都在相同的地址空间中运行。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303150136011-1642005043.png)

线程不像是**进程那样具备较强的独立性**。同一个进程中的所有线程都会有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间内每个内存地址，**因此一个线程可以读取、写入甚至擦除另一个线程的堆栈**。线程之间除了共享同一内存空间外，还具有如下不同的内容

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303150144647-770969395.png)

上图左边的是同一个进程中`每个线程共享`的内容，上图右边是`每个线程`中的内容。也就是说左边的列表是进程的属性，右边的列表是线程的属性。

和进程一样，线程可以处于下面这几种状态：**运行中、阻塞、就绪和终止（进程图中没有画）**。正在运行的线程拥有 CPU 时间片并且状态是运行中。一个被阻塞的线程会等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到有输入为止。线程通常会被阻塞，直到它等待某个外部事件的发生或者有其他线程来释放它。**线程之间的状态转换和进程之间的状态转换是一样的**。

每个线程都会有自己的堆栈，如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303150156446-968736195.png)

#### 线程实现

主要有三种实现方式，这里简单说一下，用户空间就是用户操作操作系统时所能接触到的一切内容。通常内核空间会对于用户空间来隐藏，也就意味着内核空间需要最高权限才能调用。还有就是，内核空间可以调用硬件的各种功能。

- 在用户空间中实现线程；
- 在内核空间中实现线程；
- 在用户和内核空间中混合实现线程。

##### 用户空间

第一种方法是把整个线程包放在用户空间中，内核对线程一无所知，它不知道线程的存在。所有的这类实现都有同样的通用结构

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303150212466-1530665143.png)

线程在运行时系统之上运行，运行时系统是管理线程过程的集合，包括前面提到的四个过程： pthread_create, pthread_exit, pthread_join 和 pthread_yield。

> `运行时系统(Runtime System)` 也叫做运行时环境，该运行时系统提供了程序在其中运行的环境。此环境可能会解决许多问题，包括应用程序内存的布局，**程序如何访问变量，在过程之间传递参数的机制，与操作系统的接口等等。**编译器根据特定的运行时系统进行假设以生成正确的代码。通常，运行时系统将负责设置和管理堆栈，并且会包含诸如垃圾收集，线程或语言内置的其他动态的功能。

在用户空间管理线程时，每个进程需要有其专用的`线程表(thread table)`，用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过**它仅仅记录各个线程的属性**，如每个线程的程序计数器、堆栈指针、寄存器和状态。**该线程标由运行时系统统一管理**。当一个线程转换到就绪状态或阻塞状态时，在该**线程表中存放重新启动该线程的所有信息，与内核在进程表中存放的信息完全一样。**

> 在用户空间实现线程的优势

在用户空间中实现线程要比在内核空间中实现线程具有这些方面的优势：考虑如果在线程完成时或者是在调用 `pthread_yield` 时，必要时会进程线程切换，然后线程的信息会被保存在运行时环境所提供的线程表中，然后，线程调度程序来选择另外一个需要运行的线程。保存线程的状态和调度程序都是`本地过程`，**所以启动他们比进行内核调用效率更高。因而不需要切换到内核，也就不需要上下文切换，也不需要对内存高速缓存进行刷新，因为线程调度非常便捷，因此效率比较高**。

在用户空间实现线程还有一个优势就是**它允许每个进程有自己定制的调度算法**。例如在某些应用程序中，那些具有垃圾收集线程的应用程序（知道是谁了吧）就不用担心自己线程会不会在不合适的时候停止，这是一个优势。用户线程还具有较好的可扩展性，因为内核空间中的内核线程需要一些表空间和堆栈空间，如果内核线程数量比较大，容易造成问题。

> 在用户空间实现线程的劣势

尽管在用户空间实现线程会具有一定的性能优势，但是劣势还是很明显的，你如何实现`阻塞系统调用`呢？假设在还没有任何键盘输入之前，一个线程读取键盘，让线程进行系统调用是不可能的，因为这会停止所有的线程。所以，**使用线程的一个目标是能够让线程进行阻塞调用，并且要避免被阻塞的线程影响其他线程**。

与阻塞调用类似的问题是`缺页中断`问题，实际上，计算机并不会把所有的程序都一次性的放入内存中，如果某个程序发生函数调用或者跳转指令到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令，这就称为`缺页故障`。而在对所需的指令进行读入和执行时，相关的进程就会被阻塞。如果只有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会吧整个进程阻塞直到磁盘 I/O 完成为止，尽管其他的线程是可以运行的。

另外一个问题是，如果一个线程开始运行，该线程所在进程中的其他线程都不能运行，除非第一个线程自愿的放弃 CPU，在一个单进程内部，没有时钟中断，所以不可能使用轮转调度的方式调度线程。除非其他线程能够以自己的意愿进入运行时环境，否则调度程序没有可以调度线程的机会。

##### 内核空间

现在我们考虑使用内核来实现线程的情况，此时不再需要运行时环境了。**另外，每个进程中也没有线程表。**相反，**在内核中会有用来记录系统中所有线程的线程表。**当某个线程希望创建一个新线程或撤销一个已有线程时，它会进行一个系统调用，这个系统调用通过对线程表的更新来完成线程创建或销毁工作。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303150222711-2147003107.png)

内核中的线程表持有每个线程的寄存器、状态和其他信息。这些信息和用户空间中的线程信息相同，但是位置却被放在了内核中而不是用户空间中。另外，**内核还维护了一张进程表用来跟踪系统状态。**

所有能够阻塞的调用都会通过系统调用的方式来实现，**当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运行一个另一个进程中的线程。**但是在用户实现中，运行时系统始终运行自己的线程，直到内核剥夺它的 CPU 时间片（或者没有可运行的线程存在了）为止。

由于在内核中创建或者销毁线程的开销比较大，**所以某些系统会采用可循环利用的方式来回收线程。**当某个线程被销毁时，就把它标志为不可运行的状态，但是其内部结构没有受到影响。稍后，**在必须创建一个新线程时，就会重新启用旧线程，把它标志为可用状态。**

如果某个进程中的线程造成缺页故障后，内核很容易的就能检查出来是否有其他可运行的线程，如果有的话，**在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。**这样做的缺点是系统调用的代价比较大，所以如果线程的操作（创建、终止）比较多，就会带来很大的开销。

##### 混合实现

结合用户空间和内核空间的优点，设计人员采用了一种`内核级线程`的方式，然后将用户级线程与某些或者全部内核线程多路复用起来

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303150231239-1549422367.png)

在这种模型中，编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。

### 进程通讯

进程是需要频繁的和其他进程进行交流的。例如，在一个 shell 管道中，第一个进程的输出必须传递给第二个进程，这样沿着管道进行下去。因此，进程之间如果需要通信的话，必须要使用一种良好的数据结构以至于不能被中断。下面我们会一起讨论有关 `进程间通信(Inter Process Communication, IPC)` 的问题。

关于进程间的通信，这里有三个问题

- 上面提到了第一个问题，那就是一个进程如何传递消息给其他进程。
- 第二个问题是如何确保两个或多个线程之间不会相互干扰。例如，两个航空公司都试图为不同的顾客抢购飞机上的最后一个座位。
- 第三个问题是数据的先后顺序的问题，如果进程 A 产生数据并且进程 B 打印数据。则进程 B 打印数据之前需要先等 A 产生数据后才能够进行打印。

需要注意的是，这三个问题中的后面两个问题同样也适用于线程

第一个问题在线程间比较好解决，因为它们共享一个地址空间，它们具有相同的运行时环境，可以想象你在用高级语言编写多线程代码的过程中，线程通信问题是不是比较容易解决？

另外两个问题也同样适用于线程，同样的问题可用同样的方法来解决。我们后面会慢慢讨论这三个问题，你现在脑子中大致有个印象即可。

#### 竞态条件

在一些操作系统中，**协作的进程可能共享一些彼此都能读写的公共资源**。公共资源可能在内存中也可能在一个共享文件。为了讲清楚进程间是如何通信的，这里我们举一个例子：一个后台打印程序。当一个进程需要打印某个文件时，它会将文件名放在一个特殊的`后台目录(spooler directory)`中。另一个进程 `打印后台进程(printer daemon)` 会定期的检查是否需要文件被打印，如果有的话，就打印并将该文件名从目录下删除。

假设我们的后台目录有非常多的 `槽位(slot)`，编号依次为 0，1，2，...，每个槽位存放一个文件名。**同时假设有两个共享变量：`out`，指向下一个需要打印的文件；`in`，指向目录中下个空闲的槽位。**可以把这两个文件保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0 至 3 号槽位空，4 号至 6 号槽位被占用。**在同一时刻，进程 A 和 进程 B 都决定将一个文件排队打印，情况如下**

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200303150240410-825157989.png)

`墨菲法则(Murphy)` 中说过，任何可能出错的地方终将出错，这句话生效时，可能发生如下情况。

进程 A 读到 in 的值为 7，将 7 存在一个局部变量 `next_free_slot` 中。此时发生一次时钟中断，CPU 认为进程 A 已经运行了足够长的时间，决定切换到进程 B 。进程 B 也读取 in 的值，发现是 7，然后进程 B 将 7 写入到自己的局部变量 `next_free_slot` 中，在这一时刻两个进程都认为下一个可用槽位是 7 。

进程 B 现在继续运行，它会将打印文件名写入到 slot 7 中，然后把 in 的指针更改为 8 ，然后进程 B 离开去做其他的事情

现在进程 A 开始恢复运行，由于进程 A 通过检查 `next_free_slot`也发现 slot 7 的槽位是空的，于是将打印文件名存入 slot 7 中，然后把 in 的值更新为 8 ，由于 slot 7 这个槽位中已经有进程 B 写入的值，所以进程 A 的打印文件名会把进程 B 的文件覆盖，由于打印机内部是无法发现是哪个进程更新的，它的功能比较局限，所以这时候进程 B 永远无法打印输出，类似这种情况，**即两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为竞态条件(race condition)**。调试竞态条件是一种非常困难的工作，因为绝大多数情况下程序运行良好，但在极少数的情况下会发生一些无法解释的奇怪现象

##### 互斥的概念

上面展示的情况称为**竞争条件（race condition）**，当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在**不确定性（indeterminate）**。

由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为**临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。**

我们希望这段代码是**互斥（mutualexclusion）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区**，说白了，就是这段代码执行过程中，最多只能出现一个线程。

![互斥](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/10-%E4%B8%B4%E7%95%8C%E5%8C%BA.jpg)

另外，说一下互斥也并不是只针对多线程。在多进程竞争共享资源的时候，也同样是可以使用互斥的方式来避免资源竞争造成的资源混乱。

##### 同步的概念

互斥解决了并发进程/线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程/线程进入了临界区，其他试图想进入临界区的进程/线程都会被阻塞着，直到第一个进程/线程离开了临界区。

我们都知道在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。

例子，线程 1 是负责读入数据的，而线程 2 是负责处理数据的，这两个线程是相互合作、相互依赖的。线程 2 在没有收到线程 1 的唤醒通知时，就会一直阻塞等待，当线程 1 读完数据需要把数据传给线程 2 时，线程 1 会唤醒线程 2，并把数据交给线程 2 处理。

**所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步**。

举个生活的同步例子，你肚子饿了想要吃饭，你叫妈妈早点做菜，妈妈听到后就开始做菜，但是在妈妈没有做完饭之前，你必须阻塞等待，等妈妈做完饭后，自然会通知你，接着你吃饭的事情就可以进行了。

![吃饭与做菜的同步关系](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/11-%E5%90%83%E9%A5%AD%E5%90%8C%E6%AD%A5.jpg)

注意，同步与互斥是两种不同的概念：

- 同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等
- 互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」

#### 同步方式

##### 锁

**使用加锁操作和解锁操作可以解决并发线程/进程的互斥问题。**

任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，**则线程可进入临界区**；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。

![加锁-解锁](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/12-%E4%BA%92%E6%96%A5%E9%94%81.jpg)

> 我们先来看看「忙等待锁」的实现

在说明「忙等待锁」的实现之前，先介绍现代 CPU 体系结构提供的特殊**原子操作指令 —— 测试和置位（\*Test-and-Set\*）指令**。

如果用 C 代码表示 Test-and-Set 指令，形式如下：

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/13-TestAndSet.jpg)

测试并设置指令做了下述事情:

- 把 `old_ptr` 更新为 `new` 的新值
- 返回 `old_ptr` 的旧值；

当然，**关键是这些代码是原子执行**。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」。

那什么是原子操作呢？**原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态**

我们可以运用 Test-and-Set 指令来实现「忙等待锁」，代码如下：

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/14-%E8%87%AA%E6%97%8B%E9%94%81.jpg)

我们来确保理解为什么这个锁能工作：

- 第一个场景是，首先假设一个线程在运行，调用 `lock()`，没有其他线程持有锁，所以 `flag` 是 0。当调用 `TestAndSet(flag, 1)` 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 `unlock()` 将 `flag` 清理为 0。
- 第二种场景是，当某一个线程已经持有锁（即 `flag` 为1）。本线程调用 `lock()`，然后调用 `TestAndSet(flag, 1)`，这一次返回 1。只要另一个线程一直持有锁，`TestAndSet()` 会重复返回 1，本线程会一直**忙等**。当 `flag` 终于被改为 0，本线程会调用 `TestAndSet()`，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。

很明显，**当获取不到锁时，线程就会一直 while 循环，不做任何事情**，所以就被称为「忙等待锁」，也被称为**自旋锁（\*spin lock\*）**。

这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

> 再来看看「无等待锁」的实现

无等待锁顾明思议就是获取不到锁的时候，不用自旋。

既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/15-%E6%97%A0%E7%AD%89%E5%BE%85%E9%94%81.jpg)

本次只是提出了两种简单锁的实现方式。当然，在具体操作系统实现中，会更复杂，但也离不开本例子两个基本元素。

##### 信号量

信号量是操作系统提供的一种协调共享资源访问的方法。

通常**信号量表示资源的数量**，对应的变量是一个整型（`sem`）变量。

另外，还有**两个原子操作的系统调用函数来控制信号量的**，分别是：

- *P 操作*：将 `sem` 减 `1`，相减后，如果 `sem < 0`，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；
- *V 操作*：将 `sem` 加 `1`，相加后，如果 `sem <= 0`，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；

P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。

举个类比，2 个资源的信号量，相当于 2 条火车轨道，PV 操作如下图过程：

![信号量与火车轨道](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/16-%E7%81%AB%E8%BD%A6PV%E6%93%8D%E4%BD%9C.jpg)

> 操作系统是如何实现 PV 操作的呢？

信号量数据结构与 PV 操作的算法描述如下图：

![PV 操作的算法描述](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/17-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9FPV%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0.jpg)

PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的。

> PV 操作如何使用的呢？

信号量不仅可以实现临界区的互斥访问控制，还可以线程间的事件同步。

我们先来说说如何使用**信号量实现临界区的互斥访问**：

- 为每类共享资源设置一个信号量 `s`，其初值为 `1`，表示该临界资源未被占用。

- 只要把进入临界区的操作置于 `P(s)` 和 `V(s)` 之间，即可实现进程/线程互斥：

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/18-%E4%BA%92%E6%96%A5%E4%BF%A1%E5%8F%B7%E9%87%8F.jpg)

此时，**任何想进入临界区的线程，必先在互斥信号量上执行 P 操作**，在完成对临界资源的访问后再执行 V 操作。由于互斥信号量的初始值为 1，故在第一个线程执行 P 操作后 s 值变为 0，表示临界资源为空闲，可分配给该线程，使之进入临界区。

若此时**又有第二个线程想进入临界区，也应先执行 P 操作，结果使 s 变为负值，这就意味着临界资源已被占用**，因此，第二个线程被阻塞。

并且，直到第一个线程执行 V 操作，释放临界资源而恢复 s 值为 0 后，才唤醒第二个线程，使之进入临界区，待它完成临界资源的访问后，又执行 V 操作，使 s 恢复到初始值 1。

对于两个并发线程，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示：

- 如果互斥信号量为 1，表示没有线程进入临界区；
- 如果互斥信号量为 0，表示有一个线程进入临界区；
- 如果互斥信号量为 -1，表示一个线程进入临界区，另一个线程等待进入。

通过互斥信号量的方式，就能保证临界区任何时刻只有一个线程在执行，就达到了互斥的效果。

再来，我们说说如何使用**信号量实现事件同步**。

同步的方式是设置一个信号量，其初值为 `0`。

我们把前面的「吃饭-做饭」同步的例子，用代码的方式实现一下：

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/19-%E4%BA%92%E6%96%A5%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%90%8C%E6%AD%A5%E5%AE%9E%E7%8E%B0-%E5%90%83%E9%A5%AD%E4%BE%8B%E5%AD%90.jpg)

妈妈一开始询问儿子要不要做饭时，执行的是 `P(s1)` ，相当于**询问**儿子需不需要吃饭，由于 `s1` 初始值为 0，此时 `s1` 变成 -1，表明儿子不需要吃饭，所以妈妈线程就进入**等待**状态。

当儿子肚子饿时，**执行**了 `V(s1)`，使得 `s1` 信号量从 -1 变成 0，表明此时儿子**需要**吃饭了，于是就**唤醒**了阻塞中的妈妈线程，妈妈线程就开始做饭。

接着，儿子线程执行了 `P(s2)`，相当于**询问**妈妈饭做完了吗，由于 `s2` 初始值是 0，则此时 `s2` 变成 -1，说明妈妈还没做完饭，儿子线程就**等待**状态。

最后，妈妈终于做完饭了，于是执行 `V(s2)`，`s2` 信号量从 -1 变回了 0，于是就唤醒等待中的儿子线程，**唤醒**后，儿子线程就可以进行吃饭了。

#### 经典同步问题*

##### 生产-消费者问题

桌子上有一只盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等着吃盘子中的橘子，女儿专等着吃盘子中的苹果。只有盘子空时，爸爸或妈妈才可向盘子中放一个水果。仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出水果。 用PV操作实现上述过程

![image](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image.png)

生产者-消费者问题描述：

![生产者-消费者模型](06-03-操作系统/20-生产者消费者.jpg)

- **生产者**在生成数据后，放在一个缓冲区中；
- **消费者**从缓冲区取出数据处理；
- 任何时刻，**只能有一个**生产者或消费者可以访问缓冲区；

我们对问题分析可以得出：

- 任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，**需要互斥**；
- 缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者**需要同步**。

那么我们需要三个信号量，分别是：

- 互斥信号量 `mutex`：用于互斥访问缓冲区，初始化值为 1；
- 资源信号量 `fullBuffers`：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；
- 资源信号量 `emptyBuffers`：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；

具体的实现代码：

![img](06-03-操作系统/21-生产者消费者代码示例.jpg)

如果消费者线程一开始执行 `P(fullBuffers)`，由于信号量 `fullBuffers` 初始值为 0，则此时 `fullBuffers` 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。

接着，轮到生产者执行 `P(emptyBuffers)`，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 `V(fullBuffers)` ，信号量 `fullBuffers` 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。

消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。

##### 读者-写者问题

「哲学家进餐问题」对于互斥访问有限的竞争问题（如 I/O 设备）一类的建模过程十分有用。

另外，还有个著名的问题是「读者-写者」，它为数据库访问建立了一个模型。

读者只会读取数据，不会修改数据，而写者即可以读也可以修改数据。

读者-写者的问题描述：

- 「读-读」允许：同一时刻，允许多个读者同时读
- 「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写
- 「写-写」互斥：没有其他写者时，写者才能写

接下来，提出几个解决方案来分析分析。

> 方案一

使用信号量的方式来尝试解决：

- 信号量 `wMutex`：控制写操作的互斥信号量，初始值为 1 ；
- 读者计数 `rCount`：正在进行读操作的读者个数，初始化为 0；
- 信号量 `rCountMutex`：控制对 rCount 读者计数器的互斥修改，初始值为 1；

接下来看看代码的实现：

![img](06-03-操作系统/32-读者写者-方案一示例.jpg)

上面的这种实现，是读者优先的策略，因为只要有读者正在读的状态，后来的读者都可以直接进入，如果读者持续不断进入，则写者会处于饥饿状态。

> 方案二

那既然有读者优先策略，自然也有写者优先策略：

- 只要有写者准备要写入，写者应尽快执行写操作，后来的读者就必须阻塞；
- 如果有写者持续不断写入，则读者就处于饥饿；

在方案一的基础上新增如下变量：

- 信号量 `rMutex`：控制读者进入的互斥信号量，初始值为 1；
- 信号量 `wDataMutex`：控制写者写操作的互斥信号量，初始值为 1；
- 写者计数 `wCount`：记录写者数量，初始值为 0；
- 信号量 `wCountMutex`：控制 wCount 互斥修改，初始值为 1；

具体实现如下代码：

![img](06-03-操作系统/33-读者写者-方案二示例.jpg)

注意，这里 `rMutex` 的作用，开始有多个读者读数据，它们全部进入读者队列，此时来了一个写者，执行了 `P(rMutex)` 之后，后续的读者由于阻塞在 `rMutex` 上，都不能再进入读者队列，而写者到来，则可以全部进入写者队列，因此保证了写者优先。

同时，第一个写者执行了 `P(rMutex)` 之后，也不能马上开始写，必须等到所有进入读者队列的读者都执行完读操作，通过 `V(wDataMutex)` 唤醒写者的写操作。

> 方案三

既然读者优先策略和写者优先策略都会造成饥饿的现象，那么我们就来实现一下公平策略。

公平策略：

- 优先级相同；
- 写者、读者互斥访问；
- 只能一个写者访问临界区；
- 可以有多个读者同时访问临界资源；

具体代码实现：

![img](06-03-操作系统/34-读者写者-方案三示例.jpg)

对比方案一的读者优先策略，可以发现，读者优先中只要后续有读者到达，读者就可以进入读者队列， 而写者必须等待，直到没有读者到达。

没有读者到达会导致读者队列为空，即 `rCount==0`，此时写者才可以进入临界区执行写操作。

而这里 `flag` 的作用就是阻止读者的这种特殊权限（特殊权限是只要读者到达，就可以进入读者队列）。

比如：开始来了一些读者读数据，它们全部进入读者队列，此时来了一个写者，执行 `P(falg)` 操作，使得后续到来的读者都阻塞在 `flag` 上，不能进入读者队列，这会使得读者队列逐渐为空，即 `rCount` 减为 0。

这个写者也不能立马开始写（因为此时读者队列不为空），会阻塞在信号量 `wDataMutex` 上，读者队列中的读者全部读取结束后，最后一个读者进程执行 `V(wDataMutex)`，唤醒刚才的写者，写者则继续开始进行写操作。

##### 哲学家-进餐问题

![哲学家就餐的问题](06-03-操作系统/23-哲学家进餐模型.jpg)

先来看看哲学家就餐的问题描述：

- `5` 个老大哥哲学家，闲着没事做，围绕着一张圆桌吃面；
- 巧就巧在，这个桌子只有 `5` 支叉子，每两个哲学家之间放一支叉子；
- 哲学家围在一起先思考，思考中途饿了就会想进餐；
- **奇葩的是，这些哲学家要两支叉子才愿意吃面，也就是需要拿到左右两边的叉子才进餐**；
- **吃完后，会把两支叉子放回原处，继续思考**；

那么问题来了，如何保证哲学家们的动作有序进行，而不会出现有人永远拿不到叉子呢？

> 方案一

![img](06-03-操作系统/24-哲学家进餐-方案一示例.jpg)

上面的程序，好似很自然。拿起叉子用 P 操作，代表有叉子就直接用，没有叉子时就等待其他哲学家放回叉子。

![方案一的问题](06-03-操作系统/25-哲学家进餐-方案一问题.jpg)

不过，这种解法存在一个极端的问题：**假设五位哲学家同时拿起左边的叉子，桌面上就没有叉子了， 这样就没有人能够拿到他们右边的叉子，也就说每一位哲学家都会在 `P(fork[(i + 1) % N ])` 这条语句阻塞了，很明显这发生了死锁的现象**。

> 方案二

既然「方案一」会发生同时竞争左边叉子导致死锁的现象，那么我们就在拿叉子前，加个互斥信号量，代码如下：

![img](06-03-操作系统/26-哲学家进餐-方案二示例.jpg)

上面程序中的互斥信号量的作用就在于，**只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐。**

![方案二的问题](06-03-操作系统/27-哲学家进餐-方案二问题.jpg)

方案二虽然能让哲学家们按顺序吃饭，但是每次进餐只能有一位哲学家，而桌面上是有 5 把叉子，按道理是能可以有两个哲学家同时进餐的，所以从效率角度上，这不是最好的解决方案。

> 方案三

那既然方案二使用互斥信号量，会导致只能允许一个哲学家就餐，那么我们就不用它。

另外，方案一的问题在于，会出现所有哲学家同时拿左边刀叉的可能性，那我们就避免哲学家可以同时拿左边的刀叉，采用分支结构，根据哲学家的编号的不同，而采取不同的动作。

**即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。**

![img](06-03-操作系统/28-哲学家进餐-方案三示例.jpg)

上面的程序，在 P 操作时，根据哲学家的编号不同，拿起左右两边叉子的顺序不同。另外，V 操作是不需要分支的，因为 V 操作是不会阻塞的。

![方案三可解决问题](06-03-操作系统/29-哲学家进餐-方案三-图解.jpg)

**方案三即不会出现死锁，也可以两人同时进餐。**

> 方案四

在这里再提出另外一种可行的解决方案，我们**用一个数组 state 来记录每一位哲学家的三个状态，分别是在进餐状态、思考状态、饥饿状态（正在试图拿叉子）。**

那么，**一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。**

第 `i` 个哲学家的左邻右舍，则由宏 `LEFT` 和 `RIGHT` 定义：

- LEFT : ( i + 5 - 1 ) % 5
- RIGHT : ( i + 1 ) % 5

比如 i 为 2，则 `LEFT` 为 1，`RIGHT` 为 3。

具体代码实现如下：

![img](06-03-操作系统/30-哲学家进餐-方案四示例.jpg)

上面的程序使用了一个信号量数组，每个信号量对应一位哲学家，这样在所需的叉子被占用时，想进餐的哲学家就被阻塞。

注意，每个进程/线程将 `smart_person` 函数作为主代码运行，而其他 `take_forks`、`put_forks` 和 `test` 只是普通的函数，而非单独的进程/线程。

![方案四也可解决问题](06-03-操作系统/31-哲学家进餐-方案四-图解.jpg)

方案四同样不会出现死锁，也可以两人同时进餐。

### 死锁*

> 多线程产生的问题

如果要对死锁进行一个定义的话，下面的定义比较贴切

**如果一组进程中的每个进程都在等待一个事件，而这个事件只能由该组中的另一个进程触发，这种情况会导致死锁**。

简单一点来表述一下，就是每个进程都在等待其他进程释放资源，而其他资源也在等待每个进程释放资源，这样没有进程抢先释放自己的资源，这种情况会产生死锁，所有进程都会无限的等待下去。

换句话说，死锁进程结合中的每个进程都在等待另一个死锁进程已经占有的资源。但是由于所有进程都不能运行，它们之中任何一个资源都无法释放资源，所以没有一个进程可以被唤醒。这种死锁也被称为`资源死锁(resource deadlock)`。资源死锁是最常见的类型，但不是所有的类型，我们后面会介绍其他类型，我们先来介绍资源死锁

#### [资源死锁的条件](https://www.cnblogs.com/cxuanBlog/p/13202898.html)

针对我们上面的描述，资源死锁可能出现的情况主要有

- 互斥条件：每个资源都被分配给了一个进程或者资源是可用的
- 保持和等待条件：已经获取资源的进程被认为能够获取新的资源
- 不可抢占条件：分配给一个进程的资源不能强制的从其他进程抢占资源，它只能由占有它的进程显示释放
- 循环等待：死锁发生时，系统中一定有两个或者两个以上的进程组成一个循环，循环中的每个进程都在等待下一个进程释放的资源。

发生死锁时，上面的情况必须同时会发生。如果其中任意一个条件不会成立，死锁就不会发生。可以通过破坏其中任意一个条件来破坏死锁，下面这些破坏条件就是我们探讨的重点

#### 死锁模型

Holt 在 1972 年提出对死锁进行建模，建模的标准如下：

- 圆形表示进程
- 方形表示资源

从资源节点到进程节点表示资源已经被进程占用，如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150505619-1992784794.png)

在上图中表示当前资源 R 正在被 A 进程所占用

由进程节点到资源节点的有向图表示当前进程正在请求资源，并且该进程已经被阻塞，处于等待这个资源的状态

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150516738-1296714253.png)

在上图中，表示的含义是进程 B 正在请求资源 S 。Holt 认为，死锁的描述应该如下

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150533753-253222341.png)

这是一个死锁的过程，进程 C 等待资源 T 的释放，资源 T 却已经被进程 D 占用，进程 D 等待请求占用资源 U ，资源 U 却已经被线程 C 占用，从而形成环。

总结一点：**吃着碗里的看着锅里的容易死锁**

那么如何避免死锁呢？我们还是通过死锁模型来聊一聊

假设有三个进程 (A、B、C) 和三个资源(R、S、T) 。三个进程对资源的请求和释放序列如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150540791-945596287.png)

操作系统可以任意选择一个非阻塞的程序运行，所以它可以决定运行 A 直到 A 完成工作；它可以运行 B 直到 B 完成工作；最后运行 C。

这样的顺序不会导致死锁（因为不存在对资源的竞争），但是这种情况也完全没有`并行性`。进程除了在请求和释放资源外，还要做计算和输入/输出的工作。当进程按照顺序运行时，在等待一个 I/O 时，另一个进程不能使用 CPU。所以，严格按照串行的顺序执行并不是最优越的。另一方面，如果没有进程在执行任何 I/O 操作，那么最短路径优先作业会优于轮转调度，所以在这种情况下串行可能是最优越的

现在我们假设进程会执行计算和 I/O 操作，所以轮询调度是一种合理的`调度算法`。资源请求可能会按照下面这个顺序进行

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150546471-1564230524.png)

下图是针对上面这六个步骤的资源分配图。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150557819-1050478519.png)

> 这里需要注意一个问题，为什么从资源出来的有向图指向了进程却表示**进程请求资源**呢？笔者刚开始看也有这个疑问，但是想了一下这个意思解释为进程占用资源比较合适，而进程的有向图指向资源表示进程被阻塞的意思。

在上面的第四个步骤，进程 A 正在等待资源 S；第五个步骤中，进程 B 在等待资源 T；第六个步骤中，进程 C 在等待资源 R，因此产生了环路并导致了死锁。

然而，操作系统并没有规定一定按照某种特定的顺序来执行这些进程。遇到一个可能会引起死锁的线程后，操作系统可以干脆不批准请求，并把进程挂起一直到安全状态为止。比如上图中，如果操作系统认为有死锁的可能，它可以选择不把资源 S 分配给 B ，这样 B 被挂起。这样的话操作系统会只运行 A 和 C，那么资源的请求和释放就会是下面的步骤

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150608563-568245727.png)

下图是针对上面这六个步骤的资源分配图。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150614357-1354648297.png)

在第六步执行完成后，可以发现并没有产生死锁，此时就可以把资源 S 分配给 B，因为 A 进程已经执行完毕，C 进程已经拿到了它想要的资源。进程 B 可以直接获得资源 S，也可以等待进程 C 释放资源 T 。

有四种处理死锁的策略：

- 忽略死锁带来的影响（惊呆了）
- 检测死锁并回复死锁，死锁发生时对其进行检测，一旦发生死锁后，采取行动解决问题
- 通过仔细分配资源来避免死锁
- 通过破坏死锁产生的四个条件之一来避免死锁

下面我们分别介绍一下这四种方法

#### 解决死锁

##### 鸵鸟算法

最简单的解决办法就是使用`鸵鸟算法(ostrich algorithm)`，把头埋在沙子里，假装问题根本没有发生。每个人看待这个问题的反应都不同。数学家认为死锁是不可接受的，必须通过有效的策略来防止死锁的产生。工程师想要知道问题发生的频次，系统因为其他原因崩溃的次数和死锁带来的严重后果。如果死锁发生的频次很低，而经常会由于硬件故障、编译器错误等其他操作系统问题导致系统崩溃，那么大多数工程师不会修复死锁。

##### 死锁检测和恢复*

第二种技术是死锁的检测和恢复。这种解决方式不会尝试去阻止死锁的出现。相反，这种解决方案会希望死锁尽可能的出现，在监测到死锁出现后，对其进行恢复。下面我们就来探讨一下死锁的检测和恢复的几种方式

> 每种类型一个资源的死锁检测方式

每种资源类型都有一个资源是什么意思？我们经常提到的打印机就是这样的，资源只有打印机，但是设备都不会超过一个。

可以通过构造一张资源分配表来检测这种错误，比如我们上面提到的

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150625293-1787589853.png)

的算法来检测从 P1 到 Pn 这 n 个进程中的死锁。假设资源类型为 m，E1 代表资源类型1，E2 表示资源类型 2 ，Ei 代表资源类型 i (1 <= i <= m)。E 表示的是 `现有资源向量(existing resource vector)`，代表每种已存在的资源总数。

现在我们就需要构造两个数组：C 表示的是`当前分配矩阵(current allocation matrix)` ，R 表示的是 `请求矩阵(request matrix)`。Ci 表示的是 Pi 持有每一种类型资源的资源数。所以，Cij 表示 Pi 持有资源 j 的数量。Rij 表示 Pi 所需要获得的资源 j 的数量

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150632822-407851303.png)

一般来说，已分配资源 j 的数量加起来再和所有可供使用的资源数相加 = 该类资源的总数。

死锁的检测就是基于向量的比较。每个进程起初都是没有被标记过的，算法会开始对进程做标记，进程被标记后说明进程被执行了，不会进入死锁，当算法结束时，任何没有被标记过的进程都会被判定为死锁进程。

上面我们探讨了两种检测死锁的方式，那么现在你知道怎么检测后，你何时去做死锁检测呢？一般来说，有两个考量标准：

- 每当有资源请求时就去检测，这种方式会占用昂贵的 CPU 时间。
- 每隔 k 分钟检测一次，或者当 CPU 使用率降低到某个标准下去检测。考虑到 CPU 效率的原因，如果死锁进程达到一定数量，就没有多少进程可以运行，所以 CPU 会经常空闲。

#### 死锁避免

##### 银行家算法

银行家算法是 Dijkstra 在 1965 年提出的一种调度算法，它本身是一种死锁的调度算法。它的模型是基于一个城镇中的银行家，银行家向城镇中的客户承诺了一定数量的贷款额度。算法要做的就是判断请求是否会进入一种不安全的状态。如果是，就拒绝请求，如果请求后系统是安全的，就接受该请求。

比如下面的例子，银行家一共为所有城镇居民提供了 15 单位个贷款额度，一个单位表示 1k 美元，如下所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150646933-1025059332.png)

城镇居民都喜欢做生意，所以就会涉及到贷款，每个人能贷款的最大额度不一样，在某一时刻，A/B/C/D 的贷款金额如下

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150652826-1061187177.png)

上面每个人的贷款总额加起来是 13，马上接近 15，银行家只能给 A 和 C 进行放贷，可以拖着 B 和 D、所以，可以让 A 和 C 首先完成，释放贷款额度，以此来满足其他居民的贷款。这是一种`安全`的状态。

如果每个人的请求导致总额会超过甚至接近 15 ，就会处于一种不安全的状态，如下所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200628150659472-1900546766.png)

这样，每个人还能贷款至少 2 个单位的额度，如果其中有一个人发起最大额度的贷款请求，就会使系统处于一种死锁状态。

> 这里注意一点：不安全状态并不一定引起死锁，由于客户不一定需要其最大的贷款额度，但是银行家不敢抱着这种侥幸心理。

银行家算法就是对每个请求进行检查，检查是否请求会引起不安全状态，如果不会引起，那么就接受该请求；如果会引起，那么就推迟该请求。

类似的，还有多个资源的银行家算法，读者可以自行了解。

#### 破坏死锁

在多线程编其他问题程中，我们为了防止多线程竞争共享资源而导致数据错乱，**都会在操作共享资源之前加上互斥锁，只有成功获得到锁的线程，才能操作共享资源，获取不到锁的线程就只能等待**，直到锁被释放。

那么，当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成**两个线程都在等待对方释放锁**，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了**死锁**。

举个例子，小林拿了小美房间的钥匙，而小林在自己的房间里，小美拿了小林房间的钥匙，而小美也在自己的房间里。如果小林要从自己的房间里出去，必须拿到小美手中的钥匙，但是小美要出去，又必须拿到小林手中的钥匙，这就形成了死锁。

死锁只有**同时满足**以下四个条件才会发生：

- 互斥条件；
- 持有并等待条件；
- 不可剥夺条件；
- 环路等待条件；

##### 互斥条件

互斥条件是指**多个线程不能同时使用同一个资源**。

比如下图，如果线程 A 已经持有的资源，不能再同时被线程 B 持有，如果线程 B 请求获取线程 A 已经占用的资源，那线程 B 只能等待，直到线程 A 释放了资源。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E6%9D%A1%E4%BB%B6-1724943428681-137.png)

##### 持有并等待条件

持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是**线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1**。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%8C%81%E6%9C%89%E5%B9%B6%E7%AD%89%E5%BE%85%E6%9D%A1%E4%BB%B6-1724943355663-127.png)

##### 不可剥夺条件

不可剥夺条件是指，当线程已经持有了资源 ，**在自己使用完之前不能被其他线程获取**，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%8D%E5%8F%AF%E5%89%A5%E5%A4%BA%E6%9D%A1%E4%BB%B6-1724943355663-129.png)

##### 环路等待条件

环路等待条件指的是，在死锁发生的时候，**两个线程获取资源的顺序构成了环形链**。

比如，线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经获取了资源 1，而想请求资源 2，这就形成资源请求等待的环形图。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%8E%AF%E8%B7%AF%E7%AD%89%E5%BE%85%E6%9D%A1%E4%BB%B6-1724943355663-131.png)

简单来说，死锁问题的产生是由两个或者以上线程并行执行的时候，争夺资源而互相等待造成的。**死锁只有同时满足互斥、持有并等待、不可剥夺、环路等待这四个条件的时候才会发生。**

**所以要避免死锁问题，就是要破坏其中一个条件即可**，最常用的方法就是使用资源有序分配法来破坏环路等待条件。

### CPU调度*

> 处理机也叫做CPU，也就是处理机调度

进程都希望自己能够占用 CPU 进行工作，那么这涉及到前面说过的进程上下文切换。一旦操作系统把进程切换到运行状态，也就意味着该进程占用着 CPU 在执行，**但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执行了，**于是操作系统会选择下一个要运行的进程。

选择一个进程运行这一功能是在操作系统中完成的，通常称为**调度程序**（这里的进程指只有主线程的进程，所以调度主线程就等于调度了整个进程）。那到底什么时候调度进程，或以什么原则来调度进程呢？

#### 调度时机

在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。

比如，以下状态的变化都会触发操作系统的调度：

- 从就绪态 -> 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行
- 从运行态 -> 阻塞态：当进程发生 I/O 事件而阻塞时，操作系统必须选择另外一个进程运行
- 从运行态 -> 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行

因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。

另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：

- **非抢占式调度算法**挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。
- **抢占式调度算法**挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生**时钟中断**，以便把 CPU 控制返回给调度程序进行调度，也就是常说的**时间片机制**。

#### 调度原则

原则一：如果运行的程序，发生了 I/O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，**为了提高 CPU 利用率，在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。**

原则二：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，**要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。**

原则三：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，**如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。**

原则四：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，**就绪队列中进程的等待时间也是调度程序所需要考虑的原则。**

原则五：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，**对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。**

![五种调度原则](06-03-操作系统/23-五种调度规则.jpg)

针对上面的五种调度原则，总结成如下：

- **CPU 利用率**：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；
- **系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
- **周转时间**：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；
- **等待时间**：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；
- **响应时间**：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。

说白了，这么多调度原则，目的就是要使得进程要「快」。

#### CPU调度类型

##### **作业调度**

高级调度负责**将作业从外存（辅存）调入内存。**由于内存空间有限，不能将所有作业一次性加载进内存，因此需要**按照一定的规则来决定哪些作业应优先加载。**

- 从外存中的后备队列中挑选作业，将其加载到内存。
- 为每个作业分配内存和其他必要资源，并建立进程控制块（PCB）。
- 作**业调入时会创建PCB，作业完成后会销毁PCB。**

**关注点**：主要关注如何将作业调入内存。调出操作由作业运行结束触发。

##### **内存调度**

**中级调度决定哪些处于挂起状态的进程需要被重新调入内存。**调度的频率高于高级调度，因为一个进程可能被多次调入和调出内存。

- 引入虚拟存储技术后，可以将暂时无法运行的进程转移至外存，待内存有空闲时再调入内存。
- 被挂起的进程状态记录在内存中的PCB中，PCB本身不会被调出内存。PCB包含进程在外存中的位置及状态等信息。
- 操作系统通过内存中的PCB管理挂起队列，维护对进程的监控和管理。

##### **进程调度**

**低级调度负责从就绪队列中选择一个进程，并将处理器分配给它。**是操作系统中最基本的调度类型。

- 根据调度策略选择一个就绪进程，分配CPU资源。
- 进程调度的频率很高，一般在几十毫秒内发生一次。

**关注点**：确保系统中的处理器资源得到有效利用，通过合理的调度策略来优化系统性能。

#### 典型调度算法

不同的调度算法适用的场景也是不同的。接下来，说说在**单核 CPU 系统**中常见的调度算法。

##### 先来先服务调度算法(FCFS)

最简单的一个调度算法，就是非抢占式的**先来先服务（First Come First Serve, FCFS）算法**了。

![FCFS 调度算法](06-03-操作系统/24-先来先服务.jpg)

顾名思义，先来后到，**每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，**不利于短作业。FCFS 对长作业有利**，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

![image-20240622200626956](06-03-操作系统/image-20240622200626956.png)

##### 短作业有限调度算法(SJF)

**最短作业优先（\*Shortest Job First, SJF\*）调度算法**同样也是顾名思义，它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。

![SJF 调度算法](06-03-操作系统/25-最短作业优先算法.jpg)

这显然对长作业不利，很容易造成一种极端现象。

比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

![image-20240622200755437](06-03-操作系统/image-20240622200755437.png)

##### 高响应比有限调度算法(HRRN)

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。那么，**高响应比优先 （\*Highest Response Ratio Next, HRRN\*）调度算法**主要是权衡了短作业和长作业。

**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，「响应比优先级」的计算公式：

![img](06-03-操作系统/26-响应比公式.jpg)

从上面的公式，可以发现：

- 如果**两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高**，这样短作业的进程容易被选中运行；
- 如果**两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高**，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；

![image-20240622202037455](06-03-操作系统/image-20240622202037455.png)

##### 时间片轮调度算法(RR)

最古老、最简单、最公平且使用最广的算法就是**时间片轮转（\*Round Robin, RR\*）调度算法**。

![RR 调度算法](06-03-操作系统/27-时间片轮询.jpg)

**每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。**

- 如果**时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；**
- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

- 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
- 如果设得太长又可能引起对短作业进程的响应时间变长。

一般来说，时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。

![image-20240622202425887](06-03-操作系统/image-20240622202425887.png)

##### 优先级调度算法(PAS)

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法**。

进程的优先级可以分为，静态优先级和动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

![image-20240622202503102](06-03-操作系统/image-20240622202503102.png)

##### 多级反馈队列调度算法(MFQ)

**多级反馈队列（\*Multilevel Feedback Queue\*）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![多级反馈队列](06-03-操作系统/28-多级队列.jpg)

来看看，它是如何工作的：

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，**按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾**，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**

![image-20240622202555944](06-03-操作系统/image-20240622202555944.png)

#### 举例说明调度算法

**办理业务的客户相当于进程，银行窗口工作人员相当于 CPU。**

现在，假设这个银行只有一个窗口（单核 CPU ），那么工作人员一次只能处理一个业务。

![银行办业务](06-03-操作系统/29-银行1V1.jpg)

那么最简单的处理方式，就是先来的先处理，后面来的就乖乖排队，这就是**先来先服务（FCFS）调度算法**。但是万一先来的这位老哥是来贷款的，这一谈就好几个小时，一直占用着窗口，这样后面的人只能干等，或许后面的人只是想简单的取个钱，几分钟就能搞定，却因为前面老哥办长业务而要等几个小时，你说气不气人？

![先来先服务](06-03-操作系统/30-银行-先来先服务.jpg)

有客户抱怨了，那我们就要改进，我们干脆优先给那些几分钟就能搞定的人办理业务，这就是**短作业优先（SJF）调度算法**。听起来不错，但是依然还是有个极端情况，万一办理短业务的人非常的多，这会导致长业务的人一直得不到服务，万一这个长业务是个大客户，那不就捡了芝麻丢了西瓜

![最短作业优先](06-03-操作系统/31-银行-最短作业优先.jpg)

那就公平起见，现在窗口工作人员规定，每个人我只处理 10 分钟。如果 10 分钟之内处理完，就马上换下一个人。如果没处理完，依然换下一个人，**但是客户自己得记住办理到哪个步骤了**。这个也就是**时间片轮转（RR）调度算法**。但是如果时间片设置过短，那么就会**造成大量的上下文切换**，增大了系统开销。如果时间片过长，相当于退化成 FCFS 算法了。

![时间片轮转](06-03-操作系统/32-银行-时间论片.jpg)

既然公平也可能存在问题，那银行就对客户分等级，分为普通客户、VIP 客户、SVIP 客户。只要高优先级的客户一来，就第一时间处理这个客户，这就是**最高优先级（HPF）调度算法**。但依然也会有极端的问题，万一当天来的全是高级客户，那普通客户不是没有被服务的机会，不把普通客户当人是吗？**那我们把优先级改成动态的，如果客户办理业务时间增加，则降低其优先级，如果客户等待时间增加，则升高其优先级。**

![最高优先级（静态）](06-03-操作系统/33-银行-最高优先级.jpg)

那有没有兼顾到公平和效率的方式呢？这里介绍一种算法，考虑的还算充分的，**多级反馈队列（MFQ）调度算法**，它是**时间片轮转算法和优先级算法的综合和发展。**它的工作方式：

![多级反馈队列](06-03-操作系统/34-银行-多级反馈.jpg)

- 银行设置了多个排队（就绪）队列，每个队列都有不同的优先级，**各个队列优先级从高到低**，同时每个队列执行时间片的长度也不同，**优先级越高的时间片越短**。
- 新客户（进程）来了，先进入第一级队列的末尾，按先来先服务原则排队等待被叫号（运行）。如果时间片用完客户的业务还没办理完成，则让客户进入到下一级队列的末尾，以此类推，直至客户业务办理完成。
- 当第一级队列没人排队时，就会叫号二级队列的客户。如果客户办理业务过程中，有新的客户加入到较高优先级的队列，那么此时办理中的客户需要停止办理，回到原队列的末尾等待再次叫号，因为要把窗口让给刚进入较高优先级队列的客户。

可以发现，对于要办理短业务的客户来说，可以很快的轮到并解决。对于要办理长业务的客户，一下子解决不了，就可以放到下一个队列，虽然等待的时间稍微变长了，但是轮到自己的办理时间也变长了，也可以接受，不会造成极端的现象，可以说是综合上面几种算法的优点。

## 第三章 内存管理

在现代操作系统中，进程通常使用的是虚拟内存（Virtual Memory）而不是直接的物理内存。

### 虚拟内存

介绍虚拟内存之前，先介绍**单片机**。对于单片机来说，其中的地址都是直接物理地址。所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。另外，**单片机的 CPU 是直接操作内存的「物理地址」**。

![img](06-03-操作系统/019f1f0d2d30469cbda2b8fe2cf5e622.png)

这种情况下，要想在内存中同时运行两个程序是无法达成的，**因为每一次写入都会覆盖之前烧录进物理内存中的地址，运行两个程序会立马崩溃。**

> 于是操作系统使用了虚拟内存在解决这个问题

上述问题中，两个程序都直接引用了物理地址才导致了无法运行，这里需要解决这个问题。

我们可以把**进程所使用的地址隔离**起来，使得操作系统为每一个进程独立分配一套虚拟地址，每一个进程都使用自己的地址，互不干涉。但是**它们都不能直接访问物理地址，然后问题就来到了虚拟地址是怎么落到物理内存上的了。**

![进程的中间层](06-03-操作系统/298fb68e3da94d767b02f2ed81ebf2c4.png)

**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**

如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。

于是，这里就引出了两种地址的概念：

- 我们程序所使用的内存地址叫做**虚拟内存地址**
- 实际存在硬件里面的空间地址叫**物理内存地址**

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 **CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址**，然后再通过物理地址访问内存，如下图所示：

![img](06-03-操作系统/72ab76ba697e470b8ceb14d5fc5688d9.png)

> 操作系统是如何管理虚拟地址与物理地址之间的关系？

主要有两种方式，分别是**内存分段和内存分页**，分段是比较早提出的，我们先来看看内存分段。

### 内存分段

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。**不同的段是有不同的属性的，所以就用分段（\*Segmentation\*）的形式把这些段分离出来。**

> 分段机制下，虚拟地址和物理地址是如何映射的？

分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。

![img](06-03-操作系统/a9ed979e2ed8414f9828767592aadc21.png)

段选择因子和段内偏移量：

- **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。
- 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，**如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。**

在上面，知道了虚拟地址是通过**段表**与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，**在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址**

![img](06-03-操作系统/c5e2ab63e6ee4c8db575f3c7c9c85962.png)

如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

- 第一个就是**内存碎片**的问题。
- 第二个就是**内存交换的效率低**的问题。

> 我们先来看看，分段为什么会产生内存碎片的问题？

我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：

- 游戏占用了 512MB 内存
- 浏览器占用了 128MB 内存
- 音乐占用了 256 MB 内存。

这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。

**如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。**

![img](06-03-操作系统/6142bc3c917e4a6298bdb62936e0d332.png)

> 内存分段会出现内存碎片吗？

内存碎片主要分为，内部内存碎片和外部内存碎片。

内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以**不会出现内部内存碎片**。但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以**会出现外部内存碎片**的问题。

解决「外部内存碎片」的问题就是**内存交换**。

可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。

这个内存交换空间，在 Linux 系统里，也就是我们常看到的 **Swap 空间**，这块空间是从硬盘划分出来的，**用于内存与硬盘的空间交换。**

> 分段为什么会导致内存交换效率低的问题？

对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 `Swap` 内存区域，这个过程会产生性能瓶颈。

因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。

所以，**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。

### 内存分页

分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。

要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是**内存分页**（*Paging*）。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。**虚拟地址与物理地址之间通过页表来映射**

![img](06-03-操作系统/08a8e315fedc4a858060db5cb4a654af.png)

页表是存储在内存里的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的工作。

而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

> 分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？

内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而**采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**

但是，因为内存分页机制分配内存的**最小单位是一页**，即使程序不足一页大小，我们最少只能分配一个页，所以**页内会出现内存浪费**，所以针对**内存分页机制会有内部内存碎片**的现象。

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**

![img](06-03-操作系统/388a29f45fe947e5a49240e4eff13538-20230309234651917.png)

更进一步地，**分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。**我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

> 分页机制下，虚拟地址和物理地址是如何映射的？

在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。

![img](06-03-操作系统/7884f4d8db4949f7a5bb4bbd0f452609.png)

总结一下，对于一个内存地址转换，其实就是这样三个步骤：

- 把虚拟内存地址，**切分成页号和偏移量**；
- 根据页号，从页表里面，**查询对应的物理页号**；
- **直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。**

下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图：

![img](06-03-操作系统/8f187878c809414ca2486b0b71e8880e.png)

> 简单的分页有什么缺陷吗？

有空间上的缺陷。因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。**在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页**，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 `4MB` 的内存来存储页表。

这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。**那么，`100` 个进程的话，就需要 `400MB` 的内存来存储页表，这是非常大的内存了，更别说 `64 `位的环境了。**

#### 多级页表

要解决上面的问题，就需要采用一种叫作**多级页表**（*Multi-Level Page Table*）的解决方案。

在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 `4KB` 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。

我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 `1024` 个页表（二级页表），每个表（二级页表）中包含 `1024` 个「页表项」，形成**二级分页**。如下图所示：

![img](06-03-操作系统/19296e249b2240c29f9c52be70f611d5.png)

> 分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？

当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。

每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，**在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。**

如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= `0.804MB`，这对比单级页表的 `4MB` 是不是一个巨大的节约？

> 那么为什么不分级的页表就做不到这样节约内存呢？

我们从页表的性质来看，**保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。**假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以**页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项**（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。

对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：

- 全局页目录项 PGD
- 上层页目录项 PUD
- 中间页目录项 PMD
- 页表项 PTE

![img](06-03-操作系统/四级分页.png)

#### TLB(页表缓存)

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是**带来了时间上的开销**。程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，**执行所访问的存储空间也局限于某个内存区域。**

![img](06-03-操作系统/edce58534d9342ff89f5261b1929c754.png)

我们就可以利用这一特性，**把最常访问的几个页表项存储到访问速度更快的硬件**，于是计算机科学家们，就在 CPU 芯片中，**加入了一个专门存放程序最常访问的页表项的 Cache**，这个 Cache 就是 TLB ，通常称为**页表缓存、转址旁路缓存、快表**等。

![img](06-03-操作系统/a3cdf27646b24614a64cfc5d7ccffa35.png)

在 CPU 芯片里面，**封装了内存管理单元芯片**，它用来完成地址转换和 TLB 的访问与交互。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。**TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。**

### 段页式内存管理*

> 段页结合

内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为**段页式内存管理**。

![img](06-03-操作系统/f19ebd6f70f84083b0d87cc5e9dea8e3.png)

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。用于段页式地址变换的数据结构是**每一个程序一张段表，每个段又建立一张页表**，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：

![img](06-03-操作系统/8904fb89ae0c49c4b0f2f7b5a0a7b099.png)

段页式地址变换中要得到物理地址须经过三次内存访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

**可用软、硬件相结合的方法实现段页式地址变换**，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。

### 内存分配与回收

应用程序通过 malloc 函数申请内存的时候，**实际上申请的是虚拟内存**，此时并不会分配物理内存。

当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， **CPU 就会产生缺页中断**，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。

缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。如果没有空闲的物理内存，那么内核就会开始进行**回收内存**的工作，回收的方式主要是两种：直接内存回收和后台内存回收。

- **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
- **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——**触发 OOM （Out of Memory）机制**。

OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。

申请物理内存的过程如下图：

![img](06-03-操作系统/2f61b0822b3c4a359f99770231981b07.png)

#### 哪些内存可以被回收

系统内存紧张的时候，就会进行回收内存的工作，那具体哪些内存是可以被回收的呢？

主要有两类内存可以被回收，而且它们的回收方式也不同。

- **文件页**（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，**回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存**。
- **匿名页**（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们**回收的方式是通过 Linux 的 Swap 机制**，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。

文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：

- **active_list** 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；
- **inactive_list** 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；

越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。

活跃和非活跃的内存页，按照类型的不同，又分别分为文件页和匿名页。可以从 /proc/meminfo 中，查询它们的大小，比如：

```shell
# grep表示只保留包含active的指标（忽略大小写）
# sort表示按照字母顺序排序
[root@xiaolin ~]# cat /proc/meminfo | grep -i active | sort
Active:           901456 kB
Active(anon):     227252 kB
Active(file):     674204 kB
Inactive:         226232 kB
Inactive(anon):    41948 kB
Inactive(file):   184284 kB
```

#### 回收内存带来的性能影响

在前面我们知道了回收内存有两种方式。

- 一种是后台内存回收，也就是唤醒 kswapd 内核线程，这种方式是异步回收的，不会阻塞进程。
- 一种是直接内存回收，这种方式是同步回收的，会阻塞进程，这样就会造成很长时间的延迟，以及系统的 CPU 利用率会升高，最终引起系统负荷飙高。

可被回收的内存类型有文件页和匿名页：

- 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
- 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。

可以看到，回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡。

### 内存页面置换算法

**内存页面**是用于映射虚拟内存到物理内存的基本单位。每个内存页面代表虚拟地址空间中的一个固定大小的块，并映射到物理内存中的一个页面框。每一个进程都由一个独一的内存页面。

**内存页面置换**的主要目的是在物理内存不足时，动态管理虚拟内存的使用，从而确保系统能够高效地运行多个进程。**当物理内存不够时，操作系统将不活跃的页面从物理内存移到磁盘的交换空间，以释放物理内存，然后将需要的页面加载到物理内存中。**

#### 最佳置换算法(OPT)*

最佳页面置换算法的基本思路是，**置换在未来最长时间不访问的页面**该算法需要计算内存中每一个逻辑页面的下一次访问时间，然后比较，选择未来最长时间不访问的页面

假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：

![最佳页面置换算法](06-03-操作系统/最优置换算法.png)

在这个请求的页面序列中，缺页共发生了 `7` 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 `4` 次。

这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

#### 先进先出算法(FIFO)

既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以**选择在内存驻留时间很长的页面进行中置换**，这个就是「先进先出置换」算法的思想。还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图：

![先进先出置换算法](06-03-操作系统/FIFO置换算法.png)

在这个请求的页面序列中，缺页共发生了 `10` 次，页面置换共发生了 `7` 次，跟最佳页面置换算法比较起来，性能明显差了很多。

#### 最近最久未使用算法(LRU)

最近最久未使用（*LRU*）的置换算法的基本思路是，发生缺页时，**选择最长时间没有被访问的页面进行置换**，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，**而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。**还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：

![最近最久未使用的置换算法](06-03-操作系统/LRU置换算法.png)

在这个请求的页面序列中，缺页共发生了 `9` 次，页面置换共发生了 `6` 次，跟先进先出置换算法比较起来，性能提高了一些。

虽然 LRU 在理论上是可以实现的，但代价很高。**为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。**困难的是，在每次访问内存时都必须要**更新「整个链表」。**在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

#### 时钟置换算法(CLOCK)

该算法的思路是，把所有的页面都保存在一个类似钟面的**「环形链表」**中，一个表针指向最老的页面。当发生缺页中断时，算法首先检查表针指向的页面：

- 如果它的**访问位位是 0 就淘汰该页面**，并把新的页面插入这个位置，然后把表针前移一个位置
- 如果**访问位是 1 就清除访问位**，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止

![时钟页面置换算法](06-03-操作系统/时钟置换算法.png)

了解了这个算法的工作方式，就明白为什么它被称为时钟（*Clock*）算法了。

> 页面置换算法：改进型CLOCK算法
>
> ![image-20240629204646249](06-03-操作系统/image-20240629204646249.png)

### [内存问题](https://rengwuxian.com/memory-churn/)

#### 内存抖动

在程序中，**每次创建一个对象，都会为它分配一块内存**；随着更多对象的创建，程序可用的内存逐渐减少。当已使用的内存达到一定阈值时，**垃圾回收器（Garbage Collector，GC）会启动，**回收不再使用的内存。在 Android 中，`View.onDraw()` 方法每次重绘界面时都会被调用，这意味着如果在 `onDraw()` 中编写了创建对象的代码，**那么在界面频繁刷新时，这些代码会反复创建大量的临时对象。这会导致内存使用快速上升**，并很快触发 GC 回收这些短暂的对象。

**频繁创建和回收对象并不是问题本身**。问题在于，当对象频繁创建导致内存迅速增加，**而 GC 紧接着进行回收后，内存又会迅速上升。**这种反复的过程会导致内存不断在增长和回收之间波动，形成了一种短时间内频繁发生的循环。

这种现象被称为 **内存抖动（Memory Churn）**。内存抖动不是指内存本身在震荡，而是描述内存频繁分配和回收所引起的波动和资源消耗。Android 官方文档也将其翻译为“内存抖动”。

> 抖动预防方法

- **减少短生命周期对象的创建**：使用对象池复用对象。避免在频繁调用的方法中创建对象。
- **优化内存使用**：避免不必要的对象分配。使用合适的数据结构，控制数据结构的大小。
- **改进代码设计**：选择高效算法，减少临时对象的生成。合并小对象，减少内存碎片。
- **使用内存分析工具**：监控内存使用，检测内存泄漏。进行内存优化和问题修复。
- **调整垃圾回收策略**：选择合适的GC算法。调整GC配置，优化内存管理。
- **避免频繁的UI更新**：减少UI对象创建，复用UI元素。优化渲染操作，减少对象创建开销。

#### 工作集

工作集（或驻留集）是指在某段时间间隔内，进程要访问的页面集合。经常被使用的页面需要在工作集中，而长时间不被使用的页面要从工作集中被丢弃。为了防止系统出现抖动现象，需要选择合适的工作集大小。

工作集模型的原理是：让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。如果还有空闲物理块，则可以再调一个进程到内存以增加多道程序。如果所有工作集之和增加以至于超过了可用物理块的总数，那么操作系统会暂停一个进程，将其页面调出并且将其他物理块分配给其他进程，防止出现抖动现象。

正确选择工作集的大小，对存储器的利用率和系统吞吐量的提高都将产生重要影响。

## [第四章 文件管理](https://www.cnblogs.com/cxuanBlog/p/12565601.html)

### 文件

文件是一种抽象机制，它提供了一种方式用来存储信息以及在后面进行读取。可能任何一种机制最重要的特性就是管理对象的命名方式。在创建一个文件后，它会给文件一个命名。当进程终止时，文件会继续存在，并且其他进程可以使用`名称访问该文件`。

文件命名规则对于不同的操作系统来说是不一样的，但是所有现代操作系统都允许使用 1 - 8 个字母的字符串作为合法文件名。

某些文件区分大小写字母，而大多数则不区分。`UNIX` 属于第一类；历史悠久的 `MS-DOS` 属于第二类（顺便说一句，尽管 MS-DOS 历史悠久，但 MS-DOS 仍在嵌入式系统中非常广泛地使用，因此它绝不是过时的）；因此，UNIX 系统会有三种不同的命名文件：`maria`、`Maria`、`MARIA` 。在 MS-DOS ，所有这些命名都属于相同的文件。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130731329-2085917000.png)

这里可能需要在文件系统上预留一个位置。Windows 95 和 Windows 98 都使用了 MS-DOS 文件系统，叫做 `FAT-16`，因此继承了它的一些特征，例如有关文件名的构造方法。Windows 98 引入了对 FAT-16 的一些扩展，从而导致了 `FAT-32` 的生成，但是这两者很相似。另外，Windows NT，Windows 2000，Windows XP，Windows Vista，Windows 7 和 Windows 8 都支持 `FAT` 文件系统，这种文件系统有些过时。然而，这些较新的操作系统还具有更高级的`本机文件系统(NTFS)`，有不同的特性，那就是基于 `Unicode` 编码的文件名。事实上，Windows 8 还配备了另一种文件系统，简称 `ReFS(Resilient File System)`，但这个文件系统一般应用于 Windows 8 的服务器版本。下面除非我们特殊声明，否则我们在提到 MS-DOS 和 FAT 文件系统的时候，所指的就是 Windows 的 FAT-16 和 FAT-32。这里要说一下，有一种类似 FAT 的新型文件系统，叫做 `exFAT`。它是微软公司对闪存和大文件系统开发的一种优化的 FAT 32 扩展版本。ExFAT 是现在微软唯一能够满足 `OS X`读写操作的文件系统。

许多操作系统支持两部分的文件名，它们之间用 `.` 分隔开，比如文件名 `prog.c`。原点后面的文件称为 `文件扩展名(file extension)` ，文件扩展名通常表示文件的一些信息。例如在 MS-DOS 中，文件名是 1 - 8 个字符，加上 1 - 3 个字符的可选扩展名组成。在 UNIX 中，如果有扩展名，那么扩展名的长度将由用户来决定，一个文件甚至可以包括两个或更多的扩展名，例如 `homepage.html.zip`，html 表示一个 web 网页而 .zip 表示文件`homepage.html` 已经采用 zip 程序压缩完成。一些常用的文件扩展名以及含义如下图所示

| bak  | 备份文件                             |
| ---- | ------------------------------------ |
| c    | c 源程序文件                         |
| gif  | 符合图形交换格式的图像文件           |
| hlp  | 帮助文件                             |
| html | WWW 超文本标记语言文档               |
| jpg  | 符合 JPEG 编码标准的静态图片         |
| mp3  | 符合 MP3 音频编码格式的音乐文件      |
| mpg  | 符合 MPEG 编码标准的电影             |
| o    | 目标文件（编译器输出格式，尚未链接） |
| pdf  | pdf 格式的文件                       |
| ps   | PostScript 文件                      |
| tex  | 为 TEX 格式化程序准备的输入文件      |
| txt  | 文本文件                             |
| zip  | 压缩文件                             |

在 UNIX 系统中，文件扩展名只是一种约定，操作系统并不强制采用。

名为 `file.txt` 的文件是文本文件，这个文件名更多的是提醒所有者，而不是给计算机传递信息。但是另一方面，C 编译器可能要求它编译的文件以`.c` 结尾，否则它会拒绝编译。然而，操作系统并不关心这一点。

对于可以处理多种类型的程序，约定就显得及其有用。例如 C 编译器可以编译、链接多种文件，包括 C 文件和汇编语言文件。这时扩展名就很有必要，编译器利用它们区分哪些是 C 文件，哪些是汇编文件，哪些是其他文件。因此，扩展名对于编译器判断哪些是 C 文件，哪些是汇编文件以及哪些是其他文件变得至关重要。

与 UNIX 相反，Windows 就会关注扩展名并对扩展名赋予了新的含义。`用户(或进程)` 可以在操作系统中注册`扩展名`，并且规定哪个程序能够拥有扩展名。当用户双击某个文件名时，拥有该文件名的程序就启动并运行文件。例如，双击 file.docx 启动了 Word 程序，并以 file.docx 作为初始文件。

#### 文件结构

文件的构造有多种方式。下图列出了常用的三种构造方式

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130743892-1397996394.png)

上图中的 a 是一种无结构的字节序列，操作系统不关心序列的内容是什么，操作系统能看到的就是`字节(bytes)`。其文件内容的任何含义只在用户程序中进行解释。UNIX 和 Windows 都采用这种办法。

把文件看成字节序列提供了最大的灵活性。用户程序可以向文件中写任何内容，并且可以通过任何方便的形式命名。操作系统不会为为用户写入内容提供帮助，当然也不会干扰阻塞你。对于想做特殊操作的用户来说，后者是十分重要的。所有的 UNIX 版本（包括 Linux 和 OS X）和 Windows 都使用这种文件模型。

图 b 表示在文件结构上的第一部改进。在这个模型中，文件是具有固定长度记录的序列，每个记录都有其内部结构。 把文件作为记录序列的核心思想是：**读操作返回一个记录，而写操作重写或者追加一个记录**。第三种文件结构如上图 c 所示。在这种组织结构中，文件由一颗`记录树`构成，记录树的长度不一定相同，每个记录树都在记录中的固定位置包含一个`key` 字段。这棵树按 key 进行排序，从而可以对特定的 key 进行快速查找。

在记录树的结构中，可以取出下一个记录，但是最关键的还是根据 key 搜索指定的记录。如上图 c 所示，用户可以读出指定的 `pony` 记录，而不必关心记录在文件中的确切位置。用户也可以在文件中添加新的记录。但是用户不能决定添加到何处位置，添加到何处位置是由`操作系统`决定的。

#### 文件类型

很多操作系统支持多种文件类型。例如，UNIX（同样包括 OS X）和 Windows 都具有常规的文件和目录。除此之外，UNIX 还具有`字符特殊文件(character special file)` 和 `块特殊文件(block special file)`。`常规文件(Regular files)` 是包含有用户信息的文件。用户一般使用的文件大都是常规文件，常规文件一般包括 **可执行文件、文本文件、图像文件**，从常规文件读取数据或将数据写入时，内核会根据文件系统的规则执行操作，是写入可能被延迟，记录日志或者接受其他操作。

字符特殊文件和输入/输出有关，用于串行 I/O 类设备，如终端、打印机、网络等。块特殊文件用于磁盘类设备。我们主要讨论的是常规文件。

常规文件一般分为 `ASCII` 码文件或者二进制文件。ASCII 码文件由文本组成。在一些系统中，每行都会用回车符结束（ASCII码是13，控制字符 CR，转义字符`\r`。），另外一些则会使用换行符（ASCII码是10，控制字符LF，转义字符`\n`）。一些系统（比如 Windows）两者都会使用。

ASCII 文件的优点在于`显示` 和 `打印`，还可以用任何文本编辑器进行编辑。进一步来说，如果许多应用程序使用 ASCII 码作为输入和输出，那么很容易就能够把多个程序连接起来，一个程序的输出可能是另一个程序的输入，就像管道一样。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130754341-728435191.png)

其他与 ASCII 不同的是二进制文件。打印出来的二进制文件是无法理解的。下面是一个二进制文件的格式，它取自早期的 UNIX 。尽管从技术上来看这个文件只是字节序列，但是操作系统只有在文件格式正确的情况下才会执行。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130802121-823085624.png)

个文件有五个段：文件头、征文、数据、重定位位和符号表。文件头以 `魔数(magic number)` 为开始，表明这个文件是一个可执行文件（以防止意外执行非此格式的文件）。然后是文件各个部分的大小，开始执行的标志以及一些标志位。程序本身的正文和数据在`文件头`后面，他们被加载到内存中或者重定位会根据`重定位位`进行判断。符号表则用于`调试`。

二进制文件的另外一种形式是`存档文件`，它由已编译但没有链接的库过程（模块）组合而成。每个文件都以模块头开始，其中记录了**名称、创建日期、所有者、保护码和文件大小**。和可执行文件一样，模块头也都是二进制数，将它们复制到打印机将会产生乱码。

所有的操作系统必须至少能够识别一种文件类型：它自己的可执行文件。以前的 TOPS-20 系统（用于DECsystem 20）甚至要检查要执行的任何文件的创建时间，为了定位资源文件来检查自动文件创建后是否被修改过。如果被修改过了，那么就会自动编译文件。在 UNIX 中，就是在 shell 中嵌入 `make` 程序。此时操作系统要求用户必须采用固定的文件扩展名，从而确定哪个源程序生成哪个二进制文件。

> 什么是 make 程序？在软件发展过程中，make 程序是一个自动编译的工具，它通过读取称为 `Makefiles` 的文件来自动从源代码构建可执行程序和库，该文件指定了如何导出目标程序。尽管集成开发环境和特定于语言的编译器功能也可以用于管理构建过程，但 Make 仍被广泛使用，尤其是在 Unix 和类似 Unix 的操作系统中使用。

当程序从文件中读写数据时，请求会转到`内核处理程序(kernel driver)`。如果文件是常规文件，则数据由文件系统驱动程序处理，并且通常存储在磁盘或其他存储介质上的某块区域中，从文件中读取的数据就是之前在该位置写入的数据。

当数据读取或写入到设备文件时，请求会被设备驱动程序处理。每个设备文件都有一个关联的编号，该编号标示要使用的设备驱动程序。设备处理数据的工作是它自己的事儿。

- `块设备` 也叫做块特殊文件，它的行为通常与普通文件相似：它们是字节数组，并且在给定位置读取的值是最后写入该位置的值。来自块设备的数据可以缓存在内存中，并从缓存中读取；写入可以被缓冲。块设备通常是可搜索的，块设备的概念是，相应的硬件可以一次读取或者写入整个块，例如磁盘上的一个扇区
- `字符设备` 也称为字符特殊文件，它的行为类似于管道、串行端口。将字节写入字符设备可能会导致它在屏幕上显示，在串行端口上输出，转换为声音。

`目录(Directories)` 是管理文件系统结构的系统文件。它是用于在计算机上存储文件的位置。目录位于`分层文件系统`中，例如 Linux，MS-DOS 和 UNIX。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130811281-575341292.png)

它显示所有本地和子目录（例如，cdn 目录中的 big 目录）。当前目录是 C 盘驱动器的`根目录`。之所以称为根目录，是因为该目录下没有任何内容，而其他目录都在该目录下`分支`。

#### 文件访问

早期的操作系统只有一种访问方式：`序列访问(sequential access)`。在这些系统中，进程可以按照顺序读取所有的字节或文件中的记录，但是不能跳过并乱序执行它们。顺序访问文件是可以返回到起点的，需要时可以多次读取该文件。当存储介质是磁带而不是磁盘时，顺序访问文件很方便。

在使用磁盘来存储文件时，可以不按照顺序读取文件中的字节或者记录，或者按照关键字而不是位置来访问记录。这种能够以任意次序进行读取的称为`随机访问文件(random access file)`。许多应用程序都需要这种方式。

随机访问文件对许多应用程序来说都必不可少，例如，数据库系统。如果乘客打电话预定某航班机票，订票程序必须能够直接访问航班记录，而不必先读取其他航班的成千上万条记录。

有两种方法可以指示从何处开始读取文件。第一种方法是直接使用 `read` 从头开始读取。另一种是用一个特殊的 `seek` 操作设置当前位置，在 seek 操作后，从这个当前位置顺序地开始读文件。UNIX 和 Windows 使用的是后面一种方式。

#### 文件属性

文件包括文件名和数据。除此之外，所有的操作系统还会保存其他与文件相关的信息，如文件创建的日期和时间、文件大小。我们可以称这些为文件的`属性(attributes)`。有些人也喜欢把它们称作 `元数据(metadata)`。文件的属性在不同的系统中差别很大。文件的属性只有两种状态：`设置(set)` 和 `清除(clear)`。下面是一些常用的属性

| 属性               | 含义                                   |
| ------------------ | -------------------------------------- |
| 保护               | 谁可以访问文件、以什么方式存取文件     |
| 密码（口令）       | 访问文件所需要的密码（口令）           |
| 创建者             | 创建文件者的 ID                        |
| 所有者             | 当前所有者                             |
| 只读标志           | 0 表示读/写，1 表示只读                |
| 隐藏标志           | 0 表示正常，1 表示不再列表中显示       |
| 系统标志           | 0 表示普通文件，1 表示系统文件         |
| 存档标志           | 0 表示已经备份，1 表示需要备份         |
| ASCII / 二进制标志 | 0 表示 ASCII 文件，1 表示二进制文件    |
| 随机访问标志       | 0 表示只允许顺序访问，1 表示随机访问   |
| 临时标志           | 0 表示正常，1 表示进程退出时删除该文件 |
| 加锁标志           | 0 表示未加锁，1 表示加锁               |
| 记录长度           | 一个记录中的字节数                     |
| 键的位置           | 每个记录中的键的偏移量                 |
| 键的长度           | 键字段的字节数                         |
| 创建时间           | 创建文件的日期和时间                   |
| 最后一次存取时间   | 上一次访问文件的日期和时间             |
| 最后一次修改时间   | 上一次修改文件的日期和时间             |
| 当前大小           | 文件的字节数                           |
| 最大长度           | 文件可能增长到的字节数                 |

没有一个系统能够同时具有上面所有的属性，但每个属性都在某个系统中采用。

前面四个属性（保护，口令，创建者，所有者）与文件保护有关，它们指出了谁可以访问这个文件，谁不能访问这个文件。

> `保护（File Protection）`： 用于保护计算机上有价值数据的方法。文件保护是通过密码保护文件或者仅仅向特定用户或组提供权限来实现。

在一些系统中，用户必须给出口令才能访问文件。`标志(flags)`是一些位或者短属性能够控制或者允许特定属性。

- `隐藏文件位(hidden flag)`表示该文件不在文件列表中出现。
- `存档标志位(archive flag)`用于记录文件是否备份过，由备份程序清除该标志位；若文件被修改，操作系统则设置该标志位。用这种方法，备份程序可以知道哪些文件需要备份。
- `临时标志位(temporary flag)` 允许文件被标记为是否允许自动删除当进程终止时。

`记录长度(record-length)`、`键的位置(key-position)`和`键的长度(key-length)`等字段只能出现在用关键字查找记录的文件中。它们提供了查找关键字所需要的信息。

不同的时间字段记录了文件的创建时间、最近一次访问时间以及最后一次修改时间，它们的作用不同。例如，目标文件生成后被修改的源文件需要重新编译生成目标文件。这些字段提供了必要的信息。

当前大小字段指出了当前的文件大小，一些旧的大型机操作系统要求在创建文件时指定文件呢最大值，以便让操作系统提前保留最大存储值。但是一些服务器和个人计算机却不用设置此功能。

#### 文件操作

使用文件的目的是用来存储信息并方便以后的检索。对于存储和检索，不同的系统提供了不同的操作。以下是与文件有关的最常用的一些系统调用：

1. `Create`，创建不包含任何数据的文件。调用的目的是表示文件即将建立，并对文件设置一些属性。
2. `Delete`，当文件不再需要，必须删除它以释放内存空间。为此总会有一个系统调用来删除文件。
3. `Open`，在使用文件之前，必须先打开文件。这个调用的目的是允许系统将属性和磁盘地址列表保存到主存中，用来以后的快速访问。
4. `Close`，当所有进程完成时，属性和磁盘地址不再需要，因此应关闭文件以释放表空间。很多系统限制进程打开文件的个数，以此达到鼓励用户关闭不再使用的文件。磁盘以块为单位写入，关闭文件时会强制写入最后一`块`，即使这个块空间内部还不满。
5. `Read`，数据从文件中读取。通常情况下，读取的数据来自文件的当前位置。调用者必须指定需要读取多少数据，并且提供存放这些数据的缓冲区。
6. `Write`，向文件写数据，写操作一般也是从文件的当前位置开始进行。如果当前位置是文件的末尾，则会直接追加进行写入。如果当前位置在文件中，则现有数据被覆盖，并且永远消失。
7. `append`，使用 append 只能向文件末尾添加数据。
8. `seek`，对于随机访问的文件，要指定从何处开始获取数据。通常的方法是用 seek 系统调用把当前位置指针指向文件中的特定位置。seek 调用结束后，就可以从指定位置开始读写数据了。
9. `get attributes`，进程运行时通常需要读取文件属性。
10. `set attributes`，用户可以自己设置一些文件属性，甚至是在文件创建之后，实现该功能的是 set attributes 系统调用。
11. `rename`，用户可以自己更改已有文件的名字，rename 系统调用用于这一目的。

### 目录

文件系统通常提供`目录(directories)` 或者 `文件夹(folders)` 用于记录文件的位置，在很多系统中目录本身也是文件，下面我们会讨论关于文件，他们的组织形式、属性和可以对文件进行的操作。

#### 一级目录系统

目录系统最简单的形式是有一个能够包含所有文件的目录。这种目录被称为`根目录(root directory)`，由于根目录的唯一性，所以其名称并不重要。在最早期的个人计算机中，这种系统很常见，部分原因是因为只有一个用户。下面是一个单层目录系统的例子

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130825350-980236535.png)

该目录中有四个文件。这种设计的优点在于简单，并且能够快速定位文件，毕竟只有一个地方可以检索。这种目录组织形式现在一般用于简单的嵌入式设备（如数码相机和某些便携式音乐播放器）上使用。

#### 层次目录系统

对于简单的应用而言，一般都用单层目录方式，但是这种组织形式并不适合于现代计算机，因为现代计算机含有成千上万个文件和文件夹。如果都放在根目录下，查找起来会非常困难。为了解决这一问题，出现了`层次目录系统(Hierarchical Directory Systems)`，也称为`目录树`。通过这种方式，可以用很多目录把文件进行分组。进而，如果多个用户共享同一个文件服务器，比如公司的网络系统，每个用户可以为自己的目录树拥有自己的私人根目录。这种方式的组织结构如下

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130832757-1632045200.png)

根目录含有目录 A、B 和 C ，分别属于不同的用户，其中两个用户个字创建了`子目录`。用户可以创建任意数量的子目录，现代文件系统都是按照这种方式组织的。

#### 路径名

当目录树组织文件系统时，需要有某种方法指明文件名。常用的方法有两种，第一种方式是每个文件都会用一个`绝对路径名(absolute path name)`，它由根目录到文件的路径组成。举个例子，`/usr/ast/mailbox` 意味着根目录包含一个子目录`usr`，usr 下面包含了一个 `mailbox`。绝对路径名总是以 `/` 开头，并且是唯一的。在UNIX中，路径的组件由`/`分隔。在Windows中，分隔符为`\`。 在 MULTICS 中，它是`>`。 因此，在这三个系统中，相同的路径名将被编写如下

```shell
Windows \usr\ast\mailbox 
UNIX /usr/ast/mailbox 
MULTICS >usr>ast>mailbox
```

不论使用哪种方式，如果路径名的第一个字符是分隔符，那就是绝对路径。

另外一种指定文件名的方法是 `相对路径名(relative path name)`。它常常和 `工作目录(working directory)` （也称作 `当前目录(current directory)`）一起使用。用户可以指定一个目录作为当前工作目录。例如，如果当前目录是 `/usr/ast`，那么绝对路径 `/usr/ast/mailbox`可以直接使用 `mailbox` 来引用。也就是说，如果工作目录是 `/usr/ast`，则 UNIX 命令

```
cp /usr/ast/mailbox  /usr/ast/mailbox.bak
```

和命令

```
cp mailbox mailbox.bak
```

具有相同的含义。相对路径通常情况下更加方便和简洁。而它实现的功能和绝对路径安全相同。

一些程序需要访问某个特定的文件而不必关心当前的工作目录是什么。在这种情况下，应该使用绝对路径名。

支持层次目录结构的大多数操作系统在每个目录中有两个特殊的目录项`.` 和 `..`，长读作 `dot` 和 `dotdot`。dot 指的是当前目录，dotdot 指的是其父目录（在根目录中例外，在根目录中指向自己）。可以参考下面的进程树来查看如何使用。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130842381-1762826375.png)

一个进程的工作目录是 `/usr/ast`，它可采用 `..` 沿树向上，例如，可用命令

```unix
cp ../lib/dictionary .
```

把文件 `usr/lib/dictionary` 复制到自己的目录下，第一个路径告诉系统向上找（到 usr 目录），然后向下到 `lib` 目录，找到 dictionary 文件

第二个参数 `.` 指定当前的工作目录，当 cp 命令用目录名作为最后一个参数时，则把全部的文件复制到该目录中。当然，对于上述复制，键入

```unix
cp /usr/lib/dictionary .
```

是更常用的方法。用户这里采用 `.` 可以避免键入两次 dictionary 。无论如何，键入

```unix
cp /usr/lib/dictionary dictionary
```

也可正常工作，就像键入

```unix
cp /usr/lib/dictionary /usr/lib/dictionary
```

一样。所有这些命令都能够完成同样的工作。

#### 目录操作

不同文件中管理目录的系统调用的差别比管理文件的系统调用差别大。为了了解这些系统调用有哪些以及它们怎样工作，下面给出一个例子（取自 UNIX）。

1. `Create`，创建目录，除了目录项 `.` 和 `..` 外，目录内容为空。
2. `Delete`，删除目录，只有空目录可以删除。只包含 `.` 和 `..` 的目录被认为是空目录，这两个目录项通常不能删除
3. `opendir`，目录内容可被读取。例如，未列出目录中的全部文件，程序必须先打开该目录，然后读其中全部文件的文件名。与打开和读文件相同，在读目录前，必须先打开文件。
4. `closedir`，读目录结束后，应该关闭目录用于释放内部表空间。
5. `readdir`，系统调用 readdir 返回打开目录的下一个目录项。以前也采用 read 系统调用来读取目录，但是这种方法有一个缺点：程序员必须了解和处理目录的内部结构。相反，不论采用哪一种目录结构，readdir 总是以标准格式返回一个目录项。
6. `rename`，在很多方面目录和文件都相似。文件可以更换名称，目录也可以。
7. `link`，链接技术允许在多个目录中出现同一个文件。这个系统调用指定一个存在的文件和一个路径名，并建立从该文件到路径所指名字的链接。这样，可以在多个目录中出现同一个文件。有时也被称为`硬链接(hard link)`。
8. `unlink`，删除目录项。如果被解除链接的文件只出现在一个目录中，则将它从文件中删除。如果它出现在多个目录中，则只删除指定路径名的链接，依然保留其他路径名的链接。在 UNIX 中，用于删除文件的系统调用就是 unlink。

### 文件系统的实现

在对文件有了基本认识之后，现在是时候把目光转移到文件系统的`实现`上了。之前用户关心的一直都是文件是怎样命名的、可以进行哪些操作、目录树是什么，如何找到正确的文件路径等问题。而设计人员关心的是文件和目录是怎样存储的、磁盘空间是如何管理的、如何使文件系统得以流畅运行的问题，下面我们就来一起讨论一下这些问题。

#### 文件系统布局

文件系统存储在`磁盘`中。大部分的磁盘能够划分出一到多个分区，叫做`磁盘分区(disk partitioning)` 或者是`磁盘分片(disk slicing)`。每个分区都有独立的文件系统，每块分区的文件系统可以不同。磁盘的 0 号分区称为 `主引导记录(Master Boot Record, MBR)`，用来`引导(boot)` 计算机。在 MBR 的结尾是`分区表(partition table)`。每个分区表给出每个分区由开始到结束的地址。系统管理员使用一个称为分区编辑器的程序来创建，调整大小，删除和操作分区。这种方式的一个缺点是很难适当调整分区的大小，导致一个分区具有很多可用空间，而另一个分区几乎完全被分配。

> MBR 可以用在 DOS 、Microsoft Windows 和 Linux 操作系统中。从 2010 年代中期开始，大多数新计算机都改用 GUID 分区表（GPT）分区方案。

下面是一个用 `GParted` 进行分区的磁盘，表中的分区都被认为是 `活动的(active)`。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130902527-1633306189.png)

当计算机开始引 boot 时，BIOS 读入并执行 MBR。

##### 引导块

MBR 做的第一件事就是`确定活动分区`，读入它的第一个块，称为`引导块(boot block)` 并执行。引导块中的程序将加载分区中的操作系统。为了一致性，每个分区都会从引导块开始，即使引导块不包含操作系统。引导块占据文件系统的前 4096 个字节，从磁盘上的字节偏移量 0 开始。引导块可用于启动操作系统。

> 在计算机中，引导就是启动计算机的过程，它可以通过硬件（例如按下电源按钮）或者软件命令的方式来启动。开机后，电脑的 CPU 还不能执行指令，因为此时没有软件在主存中，所以一些软件必须先被加载到内存中，然后才能让 CPU 开始执行。也就是计算机开机后，首先会进行软件的装载过程。
>
> 重启电脑的过程称为`重新引导(rebooting)`，从休眠或睡眠状态返回计算机的过程不涉及启动。

除了从引导块开始之外，磁盘分区的布局是随着文件系统的不同而变化的。通常文件系统会包含一些属性，如下

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130910338-746877753.png)

##### 超级块

紧跟在引导块后面的是 `超级块(Superblock)`，超级块 的大小为 4096 字节，从磁盘上的字节偏移 4096 开始。超级块包含文件系统的所有关键参数

- 文件系统的大小
- 文件系统中的数据块数
- 指示文件系统状态的标志
- 分配组大小

在计算机启动或者文件系统首次使用时，超级块会被读入内存。

##### 空闲空间块

接着是文件系统中`空闲块`的信息，例如，可以用位图或者指针列表的形式给出。

**BitMap 位图或者 Bit vector 位向量**

位图或位向量是一系列位或位的集合，其中每个位对应一个磁盘块，该位可以采用两个值：0和1，0表示已分配该块，而1表示一个空闲块。下图中的磁盘上给定的磁盘块实例（分配了绿色块）可以用16位的位图表示为：0000111000000110。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130917991-1463318351.png)

**使用链表进行管理**

在这种方法中，空闲磁盘块链接在一起，即一个空闲块包含指向下一个空闲块的指针。第一个磁盘块的块号存储在磁盘上的单独位置，也缓存在内存中。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130929106-21765432.png)

##### 碎片

这里不得不提一个叫做`碎片(fragment)`的概念，也称为片段。一般零散的单个数据通常称为片段。 磁盘块可以进一步分为固定大小的分配单元，片段只是在驱动器上彼此不相邻的文件片段。如果你不理解这个概念就给你举个例子。比如你用 Windows 电脑创建了一个文件，你会发现这个文件可以存储在任何地方，比如存在桌面上，存在磁盘中的文件夹中或者其他地方。你可以打开文件，编辑文件，删除文件等等。你可能以为这些都在一个地方发生，但是实际上并不是，你的硬盘驱动器可能会将文件中的一部分存储在一个区域内，另一部分存储在另外一个区域，在你打开文件时，硬盘驱动器会迅速的将文件的所有部分汇总在一起，以便其他计算机系统可以使用它。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130936788-305920891.png)

##### inode

然后在后面是一个 `inode(index node)`，也称作索引节点。它是一个数组的结构，每个文件有一个 inode，inode 非常重要，它说明了文件的方方面面。每个索引节点都存储对象数据的属性和磁盘块位置

有一种简单的方法可以找到它们 `ls -lai` 命令。让我们看一下根文件系统：

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130944549-32402469.png)

#### 文件的实现

最重要的问题是记录各个文件分别用到了哪些磁盘块。不同的系统采用了不同的方法。下面我们会探讨一下这些方式。分配背后的主要思想是`有效利用文件空间`和`快速访问文件` ，主要有三种分配方案

- 连续分配
- 链表分配
- 索引分配

##### 连续分配

最简单的分配方案是把每个文件作为一连串连续数据块存储在磁盘上。因此，在具有 1KB 块的磁盘上，将为 50 KB 文件分配 50 个连续块。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325130958632-1289204398.png)

上面展示了 40 个连续的内存块。从最左侧的 0 块开始。初始状态下，还没有装载文件，因此磁盘是空的。接着，从磁盘开始处（块 0 ）处开始写入占用 4 块长度的内存 A 。然后是一个占用 6 块长度的内存 B，会直接在 A 的末尾开始写。

注意每个文件都会在新的文件块开始写，所以如果文件 A 只占用了 `3 又 1/2` 个块，那么最后一个块的部分内存会被浪费。在上面这幅图中，总共展示了 7 个文件，每个文件都会从上个文件的末尾块开始写新的文件块。

连续的磁盘空间分配有两个优点。

- 第一，连续文件存储实现起来比较简单，只需要记住两个数字就可以：一个是第一个块的文件地址和文件的块数量。给定第一个块的编号，可以通过简单的加法找到任何其他块的编号。
- 第二点是读取性能比较强，可以通过一次操作从文件中读取整个文件。只需要一次寻找第一个块。后面就不再需要寻道时间和旋转延迟，所以数据会以全带宽进入磁盘。

因此，连续的空间分配具有`实现简单`、`高性能`的特点。

不幸的是，连续空间分配也有很明显的不足。随着时间的推移，磁盘会变得很零碎。下图解释了这种现象

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131006100-1103412932.png)

这里有两个文件 D 和 F 被删除了。当删除一个文件时，此文件所占用的块也随之释放，就会在磁盘空间中留下一些空闲块。磁盘并不会在这个位置挤压掉空闲块，因为这会复制空闲块之后的所有文件，可能会有上百万的块，这个量级就太大了。

刚开始的时候，这个碎片不是问题，因为每个新文件都会在之前文件的结尾处进行写入。然而，磁盘最终会被填满，**因此要么压缩磁盘、要么重新使用空闲块的空间**。压缩磁盘的开销太大，因此不可行；后者会维护一个空闲列表，这个是可行的。但是这种情况又存在一个问题，为空闲块匹配合适大小的文件，需要知道该文件的`最终大小`。

想象一下这种设计的结果会是怎样的。用户启动 word 进程创建文档。应用程序首先会询问最终创建的文档会有多大。这个问题必须回答，否则应用程序就不会继续执行。如果空闲块的大小要比文件的大小小，程序就会终止。因为所使用的磁盘空间已经满了。那么现实生活中，有没有使用连续分配内存的介质出现呢？

`CD-ROM` 就广泛的使用了连续分配方式。

> `CD-ROM（Compact Disc Read-Only Memory）`即只读光盘，也称作只读存储器。是一种在电脑上使用的光碟。这种光碟只能写入数据一次，信息将永久保存在光碟上，使用时通过光碟驱动器读出信息。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131013424-384537497.png)

然而 DVD 的情况会更加复杂一些。原则上，一个 `90分钟` 的电影能够被编码成一个独立的、大约 4.5 GB 的文件。但是文件系统所使用的 `UDF(Universal Disk Format)` 格式，使用一个 30 位的数来代表文件长度，从而把文件大小限制在 1 GB。所以，DVD 电影一般存储在 3、4个连续的 1 GB 空间内。这些构成单个电影中的文件块称为`扩展区(extends)`。

就像我们反复提到的，**历史总是惊人的相似**，许多年前，连续分配由于其`简单`和`高性能`被实际使用在磁盘文件系统中。后来由于用户不希望在创建文件时指定文件的大小，于是放弃了这种想法。但是随着 CD-ROM 、DVD、蓝光光盘等光学介质的出现，连续分配又流行起来。从而得出结论，`技术永远没有过时性`，现在看似很老的技术，在未来某个阶段可能又会流行起来。

##### 链表分配

第二种存储文件的方式是为每个文件构造磁盘块链表，每个文件都是磁盘块的链接列表，就像下面所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131020634-1594415974.png)

每个块的第一个字作为指向下一块的指针，块的其他部分存放数据。如果上面这张图你看的不是很清楚的话，可以看看整个的链表分配方案

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131042088-98806523.png)

与连续分配方案不同，这一方法可以充分利用每个磁盘块。除了最后一个磁盘块外，不会因为磁盘碎片而浪费存储空间。同样，在目录项中，只要存储了第一个文件块，那么其他文件块也能够被找到。

另一方面，在链表的分配方案中，尽管顺序读取非常方便，但是随机访问却很困难（这也是数组和链表数据结构的一大区别）。

还有一个问题是，由于指针会占用一些字节，每个磁盘块实际存储数据的字节数并不再是 2 的整数次幂。虽然这个问题并不会很严重，但是这种方式降低了程序运行效率。许多程序都是以长度为 2 的整数次幂来读写磁盘，由于每个块的前几个字节被指针所使用，所以要读出一个完成的块大小信息，就需要当前块的信息和下一块的信息拼凑而成，因此就引发了查找和拼接的开销。

##### 使用内存表进行链表分配

由于连续分配和链表分配都有其不可忽视的缺点。所以提出了使用内存中的表来解决分配问题。取出每个磁盘块的指针字，把它们放在内存的一个表中，就可以解决上述链表的两个不足之处。下面是一个例子

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131050887-1364607911.png)

上图表示了链表形成的磁盘块的内容。这两个图中都有两个文件，文件 A 依次使用了磁盘块地址 **4、7、 2、 10、 12**，文件 B 使用了**6、3、11 和 14**。也就是说，文件 A 从地址 4 处开始，顺着链表走就能找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺着链走到最后，也能够找到文件 B 的全部磁盘块。你会发现，这两个链表都以不属于有效磁盘编号的特殊标记（-1）结束。内存中的这种表格称为 `文件分配表(File Application Table,FAT)`。

使用这种组织方式，整个块都可以存放数据。进而，随机访问也容易很多。虽然仍要顺着链在内存中查找给定的偏移量，但是整个链都存放在内存中，所以不需要任何磁盘引用。与前面的方法相同，不管文件有多大，在目录项中只需记录一个整数（起始块号），按照它就可以找到文件的全部块。

这种方式存在缺点，那就是**必须要把整个链表放在内存中**。对于 1TB 的磁盘和 1KB 的大小的块，那么这张表需要有 10 亿项。。。每一项对应于这 10 亿个磁盘块中的一块。每项至少 3 个字节，为了提高查找速度，有时需要 4 个字节。根据系统对空间或时间的优化方案，这张表要占用 3GB 或 2.4GB 的内存。FAT 的管理方式不能较好地扩展并应用于大型磁盘中。而这正是最初 MS-DOS 文件比较实用，并仍被各个 Windows 版本所安全支持。

##### inode(索引)

最后一个记录各个文件分别包含哪些磁盘块的方法是给每个文件赋予一个称为 `inode(索引节点)` 的数据结构，每个文件都与一个 `inode` 进行关联，inode 由整数进行标识。

下面是一个简单例子的描述。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131059693-1055061333.png)

给出 inode 的长度，就能够找到文件中的所有块。

相对于在内存中使用表的方式而言，这种机制具有很大的优势。即只有在文件打开时，其 inode 才会在内存中。如果每个 inode 需要 n 个字节，最多 k 个文件同时打开，那么 inode 占有总共打开的文件是 kn 字节。仅需预留这么多空间。

这个数组要比我们上面描述的 `FAT(文件分配表)` 占用的空间小的多。原因是用于保存所有磁盘块的链接列表的表的大小与磁盘本身成正比。如果磁盘有 n 个块，那么这个表也需要 n 项。随着磁盘空间的变大，那么该表也随之`线性增长`。相反，inode 需要节点中的数组，其大小和可能需要打开的最大文件个数成正比。它与磁盘是 100GB、4000GB 还是 10000GB 无关。

inode 的一个问题是如果每个节点都会有固定大小的磁盘地址，那么文件增长到所能允许的最大容量外会发生什么？一个解决方案是**最后一个磁盘地址不指向数据块**，而是**指向一个包含额外磁盘块地址的地址**，如上图所示。一个更高级的解决方案是：有两个或者更多包含磁盘地址的块，或者指向其他存放地址的磁盘块的磁盘块。Windows 的 NTFS 文件系统采用了相似的方法，所不同的仅仅是大的 inode 也可以表示小的文件。

> NTFS 的全称是 `New Technology File System`，是微软公司开发的专用系统文件，NTFS 取代 FAT(文件分配表) 和 `HPFS(高性能文件系统)` ，并在此基础上进一步改进。例如增强对元数据的支持，使用更高级的数据结构以提升性能、可靠性和磁盘空间利用率等。

#### 目录的实现

文件只有打开后才能够被读取。在文件打开后，操作系统会使用用户提供的路径名来定位磁盘中的目录。目录项提供了查找文件磁盘块所需要的信息。根据系统的不同，提供的信息也不同，可能提供的信息是整个文件的磁盘地址，或者是第一个块的数量（两个链表方案）或 inode的数量。不过不管用那种情况，目录系统的主要功能就是 **将文件的 ASCII 码的名称映射到定位数据所需的信息上**。

与此关系密切的问题是属性应该存放在哪里。每个文件系统包含不同的文件属性，例如文件的所有者和创建时间，需要存储的位置。一种显而易见的方法是直接**把文件属性存放在目录中**。有一些系统恰好是这么做的，如下。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131107637-1404814664.png)

在这种简单的设计中，目录有一个固定大小的目录项列表，每个文件对应一项，其中包含一个固定长度的文件名，文件属性的结构体以及用以说明磁盘块位置的一个或多个磁盘地址。

对于采用 inode 的系统，会把 inode 存储在属性中而不是目录项中。在这种情况下，目录项会更短：仅仅只有文件名称和 inode 数量。这种方式如下所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131114977-1846731462.png)

到目前为止，我们已经假设文件具有较短的、固定长度的名字。在 MS-DOS 中，具有 1 - 8 个字符的基本名称和 1 - 3 个字符的可拓展名称。在 UNIX 版本 7 中，文件有 1 - 14 个字符，包括任何拓展。然而，几乎所有的现代操作系统都支持可变长度的扩展名。这是如何实现的呢？

最简单的方式是给予文件名一个长度限制，比如 255 个字符，然后使用上图中的设计，并为每个文件名保留 255 个字符空间。这种处理很简单，但是浪费了大量的目录空间，因为只有很少的文件会有那么长的文件名称。所以，需要一种其他的结构来处理。

一种可选择的方式是放弃所有目录项大小相同的想法。在这种方法中，每个目录项都包含一个固定部分，这个固定部分通常以目录项的长度开始，后面是固定格式的数据，通常包括**所有者、创建时间、保护信息和其他属性**。这个固定长度的头的后面是一个任意长度的实际文件名，如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131124010-761464377.png)

上图是 SPARC 机器使用正序放置。

> 处理机中的一串字符存放的顺序有`正序(big-endian)` 和`逆序(little-endian)` 之分。正序存放的就是高字节在前低字节在后，而逆序存放的就是低字节在前高字节在后。

这个例子中，有三个文件，分别是 `project-budget`、`personnel` 和 `foo`。每个文件名以一个特殊字符（通常是 0 ）结束，用矩形中的叉进行表示。为了使每个目录项从字的边界开始，每个文件名被填充成整数个字，如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131139000-1559039681.png)

这个方法的缺点是当文件被移除后，就会留下一块固定长度的空间，而新添加进来的文件大小不一定和空闲空间大小一致。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131146786-109243472.png)

这个问题与我们上面探讨的连续磁盘文件的问题是一样的，由于整个目录在内存中，所以只有对目录进行`紧凑拼接`操作才可节省空间。另一个问题是，一个目录项可能会分布在多个页上，**在读取文件名时可能发生缺页中断**。

处理可变长度文件名字的另外一种方法是，使目录项自身具有固定长度，而将文件名放在目录末尾的堆栈中。如上图所示的这种方式。这种方法的优点是当目录项被移除后，下一个文件将能够正常匹配移除文件的空间。当然，必须要对`堆`进行管理，因为在处理文件名的时候也会发生缺页异常。

到目前为止的所有设计中，在需要查找文件名时，所有的方案都是线性的从头到尾对目录进行搜索。对于特别长的目录，线性搜索的效率很低。提高文件检索效率的一种方式是在每个目录上使用`哈希表(hash table)`，也叫做散列表。我们假设表的大小为 n，在输入文件名时，文件名被散列在 0 和 n - 1 之间，例如，它被 n 除，并取余数。或者对构成文件名字的字求和或类似某种方法。

无论采用哪种方式，**在添加一个文件时都要对与散列值相对 应的散列表进行检查**。如果没有使用过，就会将一个指向目录项的指针指向这里。文件目录项紧跟着哈希表后面。如果已经使用过，就会构造一个链表（这种构造方式是不是和 HashMap 使用的数据结构一样？），链表的表头指针存放在表项中，并通过哈希值将所有的表项相连。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131154355-1180541609.png)

查找文件的过程和添加类似，首先对文件名进行哈希处理，在哈希表中查找是否有这个哈希值，如果有的话，就检查这条链上所有的哈希项，查看文件名是否存在。如果哈希不在链上，那么文件就不在目录中。

使用哈希表的优势是`查找非常迅速`，缺点是`管理起来非常复杂`。只有在系统中会有成千上万个目录项存在时，才会考虑使用散列表作为解决方案。

另外一种在大量目录中加快查找指令目录的方法是使用`缓存`，缓存查找的结果。在开始查找之前，会首先检查文件名是否在缓存中。如果在缓存中，那么文件就能立刻定位。当然，只有在较少的文件下进行多次查找，缓存才会发挥最大功效。

##### 共享文件

当多个用户在同一个项目中工作时，他们通常需要共享文件。如果这个共享文件同时出现在多个用户目录下，那么他们协同工作起来就很方便。下面的这张图我们在上面提到过，但是有一个更改的地方，就是 **C 的一个文件也出现在了 B 的目录下**。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131202241-1899878373.png)

如果按照如上图的这种组织方式而言，那么 B 的目录与该共享文件的联系称为 `链接(link)`。那么文件系统现在就是一个 `有向无环图(Directed Acyclic Graph, 简称 DAG)`，而不是一棵树了。

> 在图论中，如果一个有向图从任意顶点出发无法经过若干条边回到该点，则这个图是一个`有向无环图`，我们不会在此着重探讨关于图论的东西，大家可以自行 google。

将文件系统组织成为有向无环图会使得维护复杂化，但也是必须要付出的代价。

`共享文件`很方便，但这也会带来一些问题。如果目录中包含磁盘地址，则当链接文件时，**必须把 C 目录中的磁盘地址复制到 B 目录中**。如果 B 或者 C 随后又向文件中添加内容，则仅在执行追加的用户的目录中显示新写入的数据块。这种变更将会对其他用户不可见，从而破坏了共享的目的。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131209589-1288746268.png)

有两种方案可以解决这种问题。

- 第一种解决方案，磁盘块不列入目录中，而是会把磁盘块放在与文件本身相关联的小型数据结构中。目录将指向这个小型数据结构。这是 `UNIX` 中使用的方式（小型数据结构就是 inode）。
- 在第二种解决方案中，通过让系统建立一个类型为 `LINK` 的新文件，并把该文件放在 B 的目录下，使得 B 与 C 建立链接。新的文件中只包含了它所链接的文件的路径名。当 B 想要读取文件时，操作系统会检查 B 的目录下存在一个类型为 LINK 的文件，进而找到该链接的文件和路径名，然后再去读文件，这种方式称为 `符号链接(symbolic linking)`。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131225418-510827399.png)

上面的每一种方法都有各自的缺点，在第一种方式中，B 链接到共享文件时，inode 记录文件的所有者为 C。**建立一个链接并不改变所有关系**，如下图所示。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200325131233539-338096445.png)

第一开始的情况如图 a 所示，此时 C 的目录的所有者是 C ，当目录 B 链接到共享文件时，并不会改变 C 的所有者关系，只是把计数 + 1，所以此时 **系统知道目前有多少个目录指向这个文件**。然后 C 尝试删除这个文件，这个时候有个问题，如果 C 把文件移除并清除了 inode 的话，那么 B 会有一个目录项指向无效的节点。如果 inode 以后分配给另一个文件，则 B 的链接指向一个错误的文件。系统通过 inode 可知文件仍在被引用，但是没有办法找到该文件的全部目录项以删除它们。指向目录的指针不能存储在 inode 中，原因是有可能有无数个这样的目录。

所以我们能做的就是删除 C 的目录项，但是将 inode 保留下来，并将计数设置为 1 ，如上图 c 所示。c 表示的是只有 B 有指向该文件的目录项，而该文件的前者是 C 。如果系统进行记账操作的话，那么 C 将继续为该文件付账直到 B 决定删除它，如果是这样的话，只有到计数变为 0 的时刻，才会删除该文件。

对于`符号链接`，以上问题不会发生，只有真正的文件所有者才有一个指向 inode 的指针。链接到该文件上的用户只有路径名，没有指向 inode 的指针。当文件所有者删除文件时，该文件被销毁。以后若试图通过符号链接访问该文件将会失败，因为系统不能找到该文件。删除符号链接不会影响该文件。

符号链接的问题是**需要额外的开销**。必须读取包含路径的文件，然后要一个部分接一个部分地扫描路径，直到找到 inode 。这些操作也许需要很多次额外的磁盘访问。此外，每个符号链接都需要额外的 inode ，以及额外的一个磁盘块用于存储路径，虽然如果路径名很短，作为一种优化，系统可以将它存储在 inode 中。符号链接有一个优势，即只要**简单地提供一个机器的网络地址以及文件在该机器上驻留的路径**，就可以连接全球任何地方机器上的文件。

还有另一个由链接带来的问题，在符号链接和其他方式中都存在。如果允许链接，文件有两个或多个路径。查找一指定目录及其子目录下的全部文件的程序将多次定位到被链接的文件。例如，一个将某一目录及其子目录下的文件转存到磁带上的程序有可能多次复制一个被链接的文件。进而，如果接着把磁带读入另一台机器，除非转出程序具有智能，否则被链接的文件将被两次复制到磁盘上，而不是只是被链接起来。

## [第五章 OI管理](https://www.cnblogs.com/cxuanBlog/p/13156493.html)

### I/O 设备

什么是 I/O 设备？I/O 设备又叫做输入/输出设备，它是人类用来和计算机进行通信的外部硬件。输入/输出设备能够向计算机`发送数据（输出）`并从计算机`接收数据（输入）`。

`I/O 设备(I/O devices)`可以分成两种：`块设备(block devices)` 和 `字符设备(character devices)`。

#### 块设备

块设备是一个能存储`固定大小块`信息的设备，它支持**以固定大小的块，扇区或群集读取和（可选）写入数据**。每个块都有自己的`物理地址`。通常块的大小在 512 - 65536 之间。所有传输的信息都会以`连续`的块为单位。块设备的基本特征是每个块都较为对立，能够独立的进行读写。常见的块设备有 **硬盘、蓝光光盘、USB 盘**

与字符设备相比，块设备通常需要较少的引脚。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105041333-979432402-1724937571963-1.png)

> 块设备的缺点

基于给定固态存储器的块设备比基于相同类型的存储器的字节寻址要慢一些，因为必须在块的开头开始读取或写入。所以，要读取该块的任何部分，必须寻找到该块的开始，读取整个块，如果不使用该块，则将其丢弃。要写入块的一部分，必须寻找到块的开始，将整个块读入内存，修改数据，再次寻找到块的开头处，然后将整个块写回设备。

#### 字符设备

另一类 I/O 设备是`字符设备`。字符设备以`字符`为单位发送或接收一个字符流，而不考虑任何块结构。字符设备是不可寻址的，也没有任何寻道操作。常见的字符设备有 **打印机、网络设备、鼠标、以及大多数与磁盘不同的设备**。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105051293-1058585362-1724938142105-19.png)

下面显示了一些常见设备的数据速率。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105058006-1634509884.png)

#### 设备控制器

首先需要先了解一下设备控制器的概念。

设备控制器是处理 CPU 传入和传出信号的系统。设备通过插头和插座连接到计算机，并且插座连接到设备控制器。设备控制器从连接的设备处接收数据，并将其存储在控制器内部的一些`特殊目的寄存器(special purpose registers)` 也就是本地缓冲区中。

> 特殊用途寄存器，顾名思义是仅为一项任务而设计的寄存器。例如，cs，ds，gs 和其他段寄存器属于特殊目的寄存器，因为它们的存在是为了保存段号。 eax，ecx 等是一般用途的寄存器，因为你可以无限制地使用它们。 例如，你不能移动 ds，但是可以移动 eax，ebx。
>
> 通用目的寄存器比如有：eax、ecx、edx、ebx、esi、edi、ebp、esp
>
> 特殊目的寄存器比如有：cs、ds、ss、es、fs、gs、eip、flag

每个设备控制器都会有一个应用程序与之对应，设备控制器通过应用程序的接口通过中断与操作系统进行通信。设备控制器是硬件，而设备驱动程序是软件。

I/O 设备通常由`机械组件(mechanical component)`和`电子组件(electronic component)`构成。电子组件被称为 `设备控制器(device controller)`或者 `适配器(adapter)`。在个人计算机上，它通常采用`可插入（PCIe）扩展插槽`的主板上的芯片或印刷电路卡的形式。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105247174-762126961-1724938188631-24.png)

机械设备就是它自己，它的组成如下

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105255735-1864192750-1724938203294-27.png)

控制器卡上通常会有一个连接器，通向设备本身的电缆可以插入到这个连接器中，很多控制器可以操作 2 个、4 个设置 8 个相同的设备。

控制器与设备之间的接口通常是一个低层次的接口。例如，磁盘可能被格式化为 2,000,000 个扇区，每个磁道 512 字节。然而，实际从驱动出来的却是一个串行的比特流，从一个`前导符(preamble)`开始，然后是一个扇区中的 4096 位，最后是一个`校验和` 或 `ECC（错误码，Error-Correcting Code）`。前导符是在对磁盘进行格式化的时候写上去的，它包括柱面数和扇区号，扇区大小以及类似的数据，此外还包含同步信息。

控制器的任务是把串行的位流转换为字节块，并进行必要的错误校正工作。字节块通常会在控制器内部的一个缓冲区按位进行组装，然后再对校验和进行校验并证明字节块没有错误后，再将它复制到内存中。

#### 内存映射 I/O

每个控制器都会有几个寄存器用来和 CPU 进行通信。通过写入这些寄存器，操作系统可以命令设备发送数据，接收数据、开启或者关闭设备等。通过从这些寄存器中读取信息，操作系统能够知道设备的状态，是否准备接受一个新命令等。

为了控制`寄存器`，许多设备都会有`数据缓冲区(data buffer)`，来供系统进行读写。例如，在屏幕上显示一个像素的常规方法是使用一个视频 RAM，这一 RAM 基本上只是一个数据缓冲区，用来供程序和操作系统写入数据。

那么问题来了，CPU 如何与设备寄存器和设备数据缓冲区进行通信呢？存在两个可选的方式。第一种方法是，每个控制寄存器都被分配一个 `I/O 端口(I/O port)`号，这是一个 8 位或 16 位的整数。所有 I/O 端口的集合形成了受保护的 I/O 端口空间，以便普通用户程序无法访问它（只有操作系统可以访问）。使用特殊的 I/O 指令像是

```assembly
IN REG,PORT
```

CPU 可以读取控制寄存器 PORT 的内容并将结果放在 CPU 寄存器 REG 中。类似的，使用

```assembly
OUT PORT,REG
```

CPU 可以将 REG 的内容写到控制寄存器中。大多数早期计算机，包括几乎所有大型主机，如 IBM 360 及其所有后续机型，都是以这种方式工作的。

> 控制寄存器是一个处理器寄存器而改变或控制的一般行为 CPU 或其他数字设备。控制寄存器执行的常见任务包括中断控制，切换寻址模式，分页控制和协处理器控制。

在这一方案中，内存地址空间和 I/O 地址空间是不相同的，如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105306785-1826799458-1724939594782-33.png)

指令

```assembly
IN R0,4
```

和

```assembly
MOV R0,4
```

这一设计中完全不同。**前者读取 I/O端口 4 的内容并将其放入 R0，而后者读取存储器字 4 的内容并将其放入 R0**。这些示例中的 4 代表不同且不相关的地址空间。

第二个方法是 PDP-11 引入的，

> 什么是 PDP-11?
>
> ![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105316597-365777554-1724939614668-36.png)

它将**所有控制寄存器映射到内存空间**中，如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105328195-1018538957-1724939627929-39.png)

`内存映射的 I/O`是在 CPU 与其连接的外围设备之间交换数据和指令的一种方式，这种方式是处理器和 IO 设备共享同一`内存位置`的内存，即处理器和 IO 设备使用内存地址进行映射。

在大多数系统中，分配给控制寄存器的地址位于或者靠近地址的顶部附近。

下面是采用的一种混合方式

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105337070-262224664-1724939638649-42.png)

这种方式具有与内存映射 I/O 的数据缓冲区，而控制寄存器则具有单独的 I/O 端口。x86 采用这一体系结构。在 IBM PC 兼容机中，除了 0 到 64K - 1 的 I/O 端口之外，640 K 到 1M - 1 的内存地址保留给设备的数据缓冲区。

这些方案是如何工作的呢？当 CPU 想要读入一个字的时候，无论是从内存中读入还是从 I/O 端口读入，它都要将需要的地址放到总线地址线上，然后在总线的一条控制线上调用一个 `READ` 信号。还有第二条信号线来表明需要的是 I/O 空间还是内存空间。如果是内存空间，内存将响应请求。如果是 I/O 空间，那么 I/O 设备将响应请求。如果只有内存空间，那么每个内存模块和每个 I/O 设备都会将地址线和它所服务的地址范围进行比较。如果地址落在这一范围之内，它就会响应请求。绝对不会出现地址既分配给内存又分配给 I/O 设备，所以不会存在歧义和冲突。

这两种寻址控制器的方案具有不同的优缺点。先来看一下内存映射 I/O 的优点。

- 第一，如果需要特殊的 I/O 指令读写设备控制寄存器，那么访问这些寄存器需要使用汇编代码，因为在 C 或 C++ 中不存在执行 `IN` 和 `OUT`指令的方法。调用这样的过程增加了 I/O 的开销。在内存映射中，控制寄存器只是内存中的变量，在 C 语言中可以和其他变量一样进行寻址。
- 第二，对于内存映射 I/O ，不需要特殊的保护机制就能够阻止用户进程执行 I/O 操作。操作系统需要保证的是禁止把控制寄存器的地址空间放在用户的虚拟地址中就可以了。
- 第三，对于内存映射 I/O，可以引用内存的每一条指令也可以引用控制寄存器，便于引用。

在计算机设计中，几乎所有的事情都要权衡。内存映射 I/O 也是一样，它也有自己的缺点。首先，大部分计算机现在都会有一些对于内存字的缓存。缓存一个设备控制寄存器的代价是很大的。为了避免这种内存映射 I/O 的情况，硬件必须有选择性的禁用缓存，例如，在每个页面上禁用缓存，这个功能为硬件和操作系统增加了额外的复杂性，因此必须选择性的进行管理。

第二点，如果仅仅只有一个地址空间，那么所有的`内存模块(memory modules)`和所有的 I/O 设备都必须检查所有的内存引用来推断出谁来进行响应。

> 什么是内存模块？在计算中，存储器模块是其上安装有存储器集成电路的印刷电路板。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105408450-1194260609-1724939680356-45.png)

如果计算机是一种单总线体系结构的话，如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105416194-84200169-1724939688730-48.png)

让每个内存模块和 I/O 设备查看每个地址是简单易行的。

然而，现代个人计算机的趋势是专用的高速内存总线，如下图所示



![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105424396-1040278698-1724939701496-51.png)

装备这一总线是为了优化内存访问速度，x86 系统还可以有多种总线（内存、PCIe、SCSI 和 USB）。如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105506920-1667475227-1724939713339-54.png)

在内存映射机器上使用单独的内存总线的麻烦之处在于，I/O 设备无法通过内存总线查看内存地址，因此它们无法对其进行响应。此外，必须采取特殊的措施使内存映射 I/O 工作在具有多总线的系统上。一种可能的方法是首先将全部内存引用发送到内存，如果内存响应失败，CPU 再尝试其他总线。

第二种设计是在内存总线上放一个`探查设备`，放过所有潜在指向所关注的 I/O 设备的地址。此处的问题是，I/O 设备可能无法以内存所能达到的速度处理请求。

第三种可能的设计是在内存控制器中对地址进行过滤，这种设计与上图所描述的设计相匹配。这种情况下，内存控制器芯片中包含在引导时预装载的范围寄存器。这一设计的缺点是需要在引导时判定哪些内存地址而不是真正的内存地址。因而，每一设计都有支持它和反对它的论据，所以折中和权衡是不可避免的。

### 直接内存访问(DMA)

无论一个 CPU 是否具有内存映射 I/O，它都需要寻址设备控制器以便与它们交换数据。CPU 可以从 I/O 控制器每次请求一个字节的数据，但是这么做会浪费 CPU 时间，所以经常会用到一种称为`直接内存访问(Direct Memory Access)` 的方案。为了简化，我们假设 CPU 通过单一的系统总线访问所有的设备和内存，该总线连接 CPU 、内存和 I/O 设备，如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105527429-757654334-1724938316559-30.png)

现代操作系统实际更为复杂，但是原理是相同的。如果硬件有`DMA 控制器`，那么操作系统只能使用 DMA。有时这个控制器会集成到磁盘控制器和其他控制器中，但这种设计需要在每个设备上都装有一个分离的 DMA 控制器。单个的 DMA 控制器可用于向多个设备传输，这种传输往往同时进行。

不管 DMA 控制器的物理地址在哪，它都能够独立于 CPU 从而访问系统总线，如上图所示。它包含几个可由 CPU 读写的寄存器，其中包括一个内存地址寄存器，字节计数寄存器和一个或多个控制寄存器。控制寄存器指定要**使用的 I/O 端口、传送方向（从 I/O 设备读或写到 I/O 设备）、传送单位（每次一个字节或者每次一个字）以及在一次突发传送中要传送的字节数**。

为了解释 DMA 的工作原理，我们首先看一下不使用 DMA 该如何进行磁盘读取。

- 首先，控制器从`磁盘驱动器`串行地、一位一位的读一个块（一个或多个扇区），直到将整块信息放入控制器的内部缓冲区。
- 读取`校验和`以保证没有发生读错误。然后控制器会产生一个中断，当操作系统开始运行时，它会重复的从控制器的缓冲区中一次一个字节或者一个字地读取该块的信息，并将其存入内存中。

#### DMA 工作原理

当使用 DMA 后，这个过程就会变得不一样了。首先 CPU 通过设置 DMA 控制器的寄存器对它进行编程，所以 DMA 控制器知道将什么数据传送到什么地方。DMA 控制器还要向磁盘控制器发出一个命令，通知它从磁盘读数据到其内部的缓冲区并检验校验和。当有效数据位于磁盘控制器的缓冲区中时，DMA 就可以开始了。

DMA 控制器通过在总线上发出一个`读请求`到磁盘控制器而发起 DMA 传送，这是第二步。这个读请求就像其他读请求一样，磁盘控制器并不知道或者并不关心它是来自 CPU 还是来自 DMA 控制器。通常情况下，要写的内存地址在总线的地址线上，所以当磁盘控制器去匹配下一个字时，它知道将该字写到什么地方。写到内存就是另外一个总线循环了，这是第三步。当写操作完成时，磁盘控制器在总线上发出一个应答信号到 DMA 控制器，这是第四步。

然后，DMA 控制器会增加内存地址并减少字节数量。如果字节数量仍然大于 0 ，就会循环步骤 2 - 步骤 4 ，直到字节计数变为 0 。此时，DMA 控制器会打断 CPU 并告诉它传输已经完成了。操作系统开始运行时，它不会把磁盘块拷贝到内存中，因为它已经在内存中了。

不同 DMA 控制器的复杂程度差别很大。最简单的 DMA 控制器每次处理一次传输，就像上面描述的那样。更为复杂的情况是一次同时处理很多次传输，这样的控制器内部具有多组寄存器，每个通道一组寄存器。在传输每一个字之后，DMA 控制器就决定下一次要为哪个设备提供服务。DMA 控制器可能被设置为使用 `轮询算法`，或者它也有可能具有一个优先级规划设计，以便让某些设备受到比其他设备更多的照顾。假如存在一个明确的方法分辨应答信号，那么在同一时间就可以挂起对不同设备控制器的多个请求。

许多总线能够以两种模式操作：**每次一字模式和块模式**。一些 DMA 控制器也能够使用这两种方式进行操作。在前一个模式中，DMA 控制器请求传送一个字并得到这个字。如果 CPU 想要使用总线，它必须进行等待。设备可能会偷偷进入并且从 CPU 偷走一个总线周期，从而轻微的延迟 CPU。这种机制称为 `周期窃取(cycle stealing)`。

在块模式中，DMA 控制器告诉设备获取总线，然后进行一系列的传输操作，然后释放总线。这一操作的形式称为 `突发模式(burst mode)`。这种模式要比周期窃取更有效因为获取总线占用了时间，并且一次总线获得的代价是可以同时传输多个字。缺点是如果此时进行的是长时间的突发传送，有可能将 CPU 和其他设备阻塞很长的时间。

在我们讨论的这种模型中，有时被称为 `飞越模式(fly-by mode)`，DMA 控制器会告诉设备控制器把数据直接传递到内存。一些 DMA 控制器使用的另一种模式是让设备控制器将字发送给 DMA 控制器，然后 DMA 控制器发出第二条总线请求，将字写到任何可以写入的地方。采用这种方案，每个传输的字都需要一个额外的总线周期，但是更加灵活，因为它还可以执行设备到设备的复制，甚至是内存到内存的复制（通过事先对内存进行读取，然后对内存进行写入）。

大部分的 DMA 控制器使用物理地址进行传输。使用物理地址需要操作系统将目标内存缓冲区的虚拟地址转换为物理地址，并将该物理地址写入 DMA 控制器的地址寄存器中。另一种方案是一些 DMA 控制器将虚拟地址写入 DMA 控制器中。然后，DMA 控制器必须使用 MMU 才能完成虚拟到物理的转换。仅当 MMU 是内存的一部分而不是 CPU 的一部分时，才可以将虚拟地址放在总线上。

### 中断

在一台个人计算机体系结构中，中断结构会如下所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105553778-2014729477-1724937637742-4.png)

当一个 I/O 设备完成它的工作后，它就会产生一个中断（默认操作系统已经开启中断），它通过在总线上声明已分配的信号来实现此目的。主板上的中断控制器芯片会检测到这个信号，然后执行中断操作。

如果在中断前没有其他中断操作阻塞的话，中断控制器将立刻对中断进行处理，如果在中断前还有其他中断操作`正在执行`，或者有其他设备发出级别`更高`的中断信号的话，那么这个设备将暂时不会处理。在这种情况下，该设备会继续在总线上置起中断信号，直到得到 CPU 服务。

为了处理中断，中断控制器在地址线上放置一个数字，指定要关注的设备是哪个，并声明一个信号以中断 CPU。中断信号导致 CPU 停止当前正在做的工作并且开始做其他事情。地址线上会有一个指向`中断向量表` 的索引，用来获取下一个程序计数器。这个新获取的程序计数器也就表示着程序将要开始，它会指向程序的开始处。一般情况下，陷阱和中断从这一点上看使用相同的机制，并且常常共享相同的中断向量。中断向量的位置可以硬连线到机器中，也可以位于内存中的任何位置，由 CPU 寄存器指向其起点。

中断服务程序开始运行后，中断服务程序通过将某个值写入中断控制器的 I/O 端口来确认中断。告诉它中断控制器可以自由地发出另一个中断。通过让 CPU 延迟响应来达到多个中断同时到达 CPU 涉及到竞争的情况发生。一些老的计算机没有集中的中断控制器，通常每个设备请求自己的中断。

硬件通常在服务程序开始前保存当前信息。对于不同的 CPU 来说，哪些信息需要保存以及保存在哪里差别很大。不管其他的信息是否保存，程序计数器必须要被保存，这对所有的 CPU 来说都是相同的，以此来恢复中断的进程。所有可见寄存器和大量内部寄存器也应该被保存。

上面说到硬件应该保存当前信息，那么保存在哪里是个问题，一种选择是将其放入到内部寄存器中，在需要时操作系统可以读出这些内部寄存器。这种方法会造成的问题是：一段时间内设备无法响应，直到所有的内部寄存器中存储的信息被读出后，才能恢复运行，以免第二个内部寄存器重写内部寄存器的状态。

第二种方式是在堆栈中保存信息，这也是大部分 CPU 所使用的方式。但是，这种方法也存在问题，因为使用的堆栈不确定，如果使用的是`当前堆栈`，则它很可能是用户进程的堆栈。堆栈指针甚至不合法，这样当硬件试图在它所指的地址处写入时，将会导致致命错误。如果使用的是内核堆栈，堆栈指针是合法的并且指向一个固定的页面，这样的机会可能会更大。然而，切换到内核态需要切换 MMU 上下文，并且可能使高速缓存或者 TLB 失效。静态或动态重新装载这些东西将增加中断处理的时间，浪费 CPU 时间。

#### 精确中断和不精确中断

另一个问题是：现代 CPU 大量的采用`流水线`并且有时还采用`超标量(内部并行)`。在一些老的系统中，每条指令执行完毕后，微程序或硬件将检查是否存在未完成的中断。如果存在，那么程序计数器和 PSW 将被压入堆栈中开始中断序列。在中断程序运行之后，旧的 PSW 和程序计数器将从堆栈中弹出恢复先前的进程。

下面是一个流水线模型

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105602282-194622243-1724937756913-7.png)

在流水线满的时候出现一个中断会发生什么情况？许多指令正处于不同的执行阶段，中断出现时，程序计数器的值可能无法正确地反应已经执行过的指令和尚未执行的指令的边界。事实上，许多指令可能部分执行力，不同的指令完成的程度或多或少。在这种情况下，a程序计数器更有可能反应的是将要被取出并压入流水线的下一条指令的地址，而不是刚刚被执行单元处理过的指令的地址。

在超标量的设计中，可能更加糟糕

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105609768-1457189047-1724937779758-10.png)

每个指令都可以分解成为微操作，微操作有可能乱序执行，这取决于内部资源（如功能单元和寄存器）的可用性。当中断发生时，某些很久以前启动的指令可能还没开始执行，而最近执行的指令可能将要马上完成。在中断信号出现时，可能存在许多指令处于不同的完成状态，它们与程序计数器之间没有什么关系。

使机器处于良好状态的中断称为`精确中断(precise interrupt)`。这样的中断具有四个属性：

- PC （程序计数器）保存在一个已知的地方
- PC 所指向的指令之前所有的指令已经完全执行
- PC 所指向的指令之后所有的指令都没有执行
- PC 所指向的指令的执行状态是已知的

不满足以上要求的中断称为 `不精确中断(imprecise interrupt)`，不精确中断让人很头疼。上图描述了不精确中断的现象。指令的执行时序和完成度具有不确定性，而且恢复起来也非常麻烦。

### IO 软件原理

#### 设备独立性

I/O 软件设计一个很重要的目标就是`设备独立性(device independence)`。啥意思呢？这意味着**我们能够编写访问任何设备的应用程序，而不用事先指定特定的设备**。比如你编写了一个能够从设备读入文件的应用程序，那么这个应用程序可以从硬盘、DVD 或者 USB 进行读入，不必再为每个设备定制应用程序。这其实就体现了设备独立性的概念。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105630109-786829372-1724940067027-57.png)

再比如说你可以输入一条下面的指令

```shell
sort 输入 输出
```

那么上面这个 `输入` 就可以接收来自任意类型的磁盘或者键盘，并且 `输出` 可以写入到任意类型的磁盘或者屏幕。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105643731-1807552632-1724940093638-60.png)

计算机操作系统是这些硬件的媒介，因为不同硬件它们的指令序列不同，所以需要操作系统来做指令间的转换。

与设备独立性密切相关的一个指标就是`统一命名(uniform naming)`。设备的代号应该是一个整数或者是字符串，它们不应该依赖于具体的设备。在 UNIX 中，所有的磁盘都能够被集成到文件系统中，所以用户不用记住每个设备的具体名称，直接记住对应的路径即可，如果路径记不住，也可以通过 `ls` 等指令找到具体的集成位置。举个例子来说，比如一个 USB 磁盘被挂载到了 `/usr/cxuan/backup` 下，那么你把文件复制到 `/usr/cxuan/backup/device` 下，就相当于是把文件复制到了磁盘中，通过这种方式，实现了向任何磁盘写入文件都相当于是向指定的路径输出文件。

#### 错误处理

除了`设备独立性`外，I/O 软件实现的第二个重要的目标就是`错误处理(error handling)`。通常情况下来说，错误应该交给`硬件`层面去处理。如果设备控制器发现了读错误的话，它会尽可能的去修复这个错误。如果设备控制器处理不了这个问题，那么设备驱动程序应该进行处理，设备驱动程序会再次尝试读取操作，很多错误都是偶然性的，如果设备驱动程序无法处理这个错误，才会把错误向上抛到硬件层面（上层）进行处理，很多时候，上层并不需要知道下层是如何解决错误的。这就很像项目经理不用把每个决定都告诉老板；程序员不用把每行代码如何写告诉项目经理。这种处理方式不够透明。

#### 同步和异步传输

I/O 软件实现的第三个目标就是 `同步(synchronous)` 和 `异步(asynchronous，即中断驱动)`传输。这里先说一下同步和异步是怎么回事吧。

同步传输中数据通常以块或帧的形式发送。发送方和接收方在数据传输之前应该具有`同步时钟`。而在异步传输中，数据通常以字节或者字符的形式发送，异步传输则不需要同步时钟，但是会在传输之前向数据添加`奇偶校验位`。下面是同步和异步的主要区别

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105656790-107842032-1724940120177-63.png)

回到正题。大部分`物理IO(physical I/O)` 是异步的。物理 I/O 中的 CPU 是很聪明的，CPU 传输完成后会转而做其他事情，它和中断心灵相通，等到中断发生后，CPU 才会回到传输这件事情上来。

> I/O 分为两种：物理I/O 和 `逻辑I/O(Logical I/O)`。
>
> 物理 I/O 通常是从磁盘等存储设备实际获取数据。逻辑 I/O 是对存储器（块，缓冲区）获取数据。

#### 缓冲

I/O 软件的最后一个问题是`缓冲(buffering)`。通常情况下，从一个设备发出的数据不会直接到达最后的设备。其间会经过一系列的校验、检查、缓冲等操作才能到达。举个例子来说，从网络上发送一个数据包，会经过一系列检查之后首先到达缓冲区，从而消除缓冲区填满速率和缓冲区过载。

#### 共享和独占

I/O 软件引起的最后一个问题就是共享设备和独占设备的问题。有些 I/O 设备能够被许多用户共同使用。一些设备比如磁盘，让多个用户使用一般不会产生什么问题，但是某些设备必须具有独占性，即只允许单个用户使用完成后才能让其他用户使用。

下面，我们来探讨一下如何使用程序来控制 I/O 设备。一共有三种控制 I/O 设备的方法

- 使用程序控制 I/O
- 使用中断驱动 I/O
- 使用 DMA 驱动 I/O

### 使用程序控制 I/O

使用程序控制 I/O 又被称为 `可编程I/O`，它是指由 CPU 在驱动程序软件控制下启动的数据传输，来访问设备上的寄存器或者其他存储器。CPU 会发出命令，然后等待 I/O 操作的完成。由于 CPU 的速度比 I/O 模块的速度快很多，因此可编程 I/O 的问题在于，CPU 必须等待很长时间才能等到处理结果。CPU 在等待时会采用`轮询(polling)`或者 `忙等(busy waiting)` 的方式，结果，整个系统的性能被严重拉低。可编程 I/O 十分简单，如果需要等待的时间非常短的话，可编程 I/O 倒是一个很好的方式。一个可编程的 I/O 会经历如下操作

- CPU 请求 I/O 操作
- I/O 模块执行响应
- I/O 模块设置状态位
- CPU 会定期检查状态位
- I/O 不会直接通知 CPU 操作完成
- I/O 也不会中断 CPU
- CPU 可能会等待或在随后的过程中返回

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105710521-1232183013-1724940205212-66.png)

#### 使用中断驱动 I/O

鉴于上面可编程 I/O 的缺陷，我们提出一种改良方案，我们想要在 CPU 等待 I/O 设备的同时，能够做其他事情，等到 I/O 设备完成后，它就会产生一个中断，这个中断会停止当前进程并保存当前的状态。一个可能的示意图如下

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105720818-243773612-1724940220314-69.png)

尽管中断减轻了 CPU 和 I/O 设备的等待时间的负担，但是由于还需要在 CPU 和 I/O 模块之前进行大量的逐字传输，因此在大量数据传输中效率仍然很低。下面是中断的基本操作

- CPU 进行读取操作
- I/O 设备从外围设备获取数据，同时 CPU 执行其他操作
- I/O 设备中断通知 CPU
- CPU 请求数据
- I/O 模块传输数据

所以我们现在着手需要解决的就是 CPU 和 I/O 模块间数据传输的效率问题。

#### 使用 DMA 的 I/O

DMA 的中文名称是直接内存访问，它意味着 CPU 授予 I/O 模块权限在不涉及 CPU 的情况下读取或写入内存。也就是 DMA 可以不需要 CPU 的参与。这个过程由称为 DMA 控制器（DMAC）的芯片管理。由于 DMA 设备可以直接在内存之间传输数据，而不是使用 CPU 作为中介，因此可以缓解总线上的拥塞。DMA 通过允许 CPU 执行任务，同时 DMA 系统通过系统和内存总线传输数据来提高系统并发性。

### I/O 层次结构

I/O 软件通常组织成四个层次，它们的大致结构如下图所示

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105736117-1769162339-1724940689053-72.png)

每一层和其上下层都有明确的功能和接口。下面我们采用和计算机网络相反的套路，即自下而上的了解一下这些程序。

下面是另一幅图，这幅图显示了输入/输出软件系统所有层及其主要功能。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105746420-1301086113-1724940700911-75.png)

下面我们具体的来探讨一下上面的层次结构

#### 中断处理程序

在计算机系统中，中断就像女人的脾气一样无时无刻都在产生，中断的出现往往是让人很不爽的。中断处理程序又被称为`中断服务程序` 或者是 `ISR(Interrupt Service Routines)`，它是最靠近硬件的一层。中断处理程序由硬件中断、软件中断或者是软件异常启动产生的中断，用于实现设备驱动程序或受保护的操作模式（例如系统调用）之间的转换。

中断处理程序负责处理中断发生时的所有操作，操作完成后阻塞，然后启动中断驱动程序来解决阻塞。通常会有三种通知方式，依赖于不同的具体实现

- 信号量实现中：在信号量上使用 `up` 进行通知；
- 管程实现：对管程中的条件变量执行 `signal` 操作
- 还有一些情况是发送一些消息

不管哪种方式都是为了让阻塞的中断处理程序恢复运行。

中断处理方案有很多种，下面是 《**ARM System Developer’s Guide**

**Designing and Optimizing System Software**》列出来的一些方案

- `非嵌套`的中断处理程序按照顺序处理各个中断，非嵌套的中断处理程序也是最简单的中断处理
- `嵌套`的中断处理程序会处理多个中断而无需分配优先级
- `可重入`的中断处理程序可使用优先级处理多个中断
- `简单优先级`中断处理程序可处理简单的中断
- `标准优先级`中断处理程序比低优先级的中断处理程序在更短的时间能够处理优先级更高的中断
- `高优先级` 中断处理程序在短时间能够处理优先级更高的任务，并直接进入特定的服务例程。
- `优先级分组`中断处理程序能够处理不同优先级的中断任务

下面是一些通用的中断处理程序的步骤，不同的操作系统实现细节不一样

- 保存所有没有被中断硬件保存的寄存器
- 为中断服务程序设置上下文环境，可能包括设置 `TLB`、`MMU` 和页表，如果不太了解这三个概念，请参考另外一篇文章
- 为中断服务程序设置栈
- 对中断控制器作出响应，如果不存在集中的中断控制器，则继续响应中断
- 把寄存器从保存它的地方拷贝到进程表中
- 运行中断服务程序，它会从发出中断的设备控制器的寄存器中提取信息
- 操作系统会选择一个合适的进程来运行。如果中断造成了一些优先级更高的进程变为就绪态，则选择运行这些优先级高的进程
- 为进程设置 MMU 上下文，可能也会需要 TLB，根据实际情况决定
- 加载进程的寄存器，包括 PSW 寄存器
- 开始运行新的进程

上面我们罗列了一些大致的中断步骤，不同性质的操作系统和中断处理程序能够处理的中断步骤和细节也不尽相同，下面是一个嵌套中断的具体运行步骤

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105805710-3284043-1724940727159-78.png)

#### 设备驱动程序

在上面的文章中我们知道了设备控制器所做的工作。我们知道每个控制器其内部都会有寄存器用来和设备进行沟通，发送指令，读取设备的状态等。

因此，每个连接到计算机的 I/O 设备都需要有某些特定设备的代码对其进行控制，例如鼠标控制器需要从鼠标接受指令，告诉下一步应该移动到哪里，键盘控制器需要知道哪个按键被按下等。这些提供 I/O 设备到设备控制器转换的过程的代码称为 `设备驱动程序(Device driver)`。

为了能够访问设备的硬件，实际上也就意味着，设备驱动程序通常是操作系统内核的一部分，至少现在的体系结构是这样的。但是也可以构造`用户空间`的设备驱动程序，通过系统调用来完成读写操作。这样就避免了一个问题，有问题的驱动程序会干扰内核，从而造成崩溃。所以，在用户控件实现设备驱动程序是构造系统稳定性一个非常有用的措施。`MINIX 3` 就是这么做的。下面是 MINI 3 的调用过程

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105814467-1052713584-1724940742491-81.png)

然而，大多数桌面操作系统要求驱动程序必须运行在内核中。

操作系统通常会将驱动程序归为 `字符设备` 和 `块设备`，我们上面也介绍过了

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105827317-965824659-1724940770318-84.png)

在 UNIX 系统中，操作系统是一个`二进制程序`，包含需要编译到其内部的所有驱动程序，如果你要对 UNIX 添加一个新设备，需要重新编译内核，将新的驱动程序装到二进制程序中。

然而随着大多数个人计算机的出现，由于 I/O 设备的广泛应用，上面这种静态编译的方式不再有效，因此，从 `MS-DOS` 开始，操作系统转向驱动程序在执行期间动态的装载到系统中。

设备驱动程序具有很多功能，比如接受读写请求，对设备进行初始化、管理电源和日志、对输入参数进行有效性检查等。

设备驱动程序接受到读写请求后，会检查当前设备是否在使用，如果设备在使用，请求被排入队列中，等待后续的处理。如果此时设备是空闲的，驱动程序会检查硬件以了解请求是否能够被处理。在传输开始前，会启动设备或者马达。等待设备就绪完成，再进行实际的控制。**控制设备就是对设备发出指令**。

发出命令后，设备控制器便开始将它们写入控制器的`设备寄存器`。在将每个命令写入控制器后，会检查控制器是否接受了这条命令并准备接受下一个命令。一般控制设备会发出一系列的指令，这称为`指令序列`，设备控制器会依次检查每个命令是否被接受，下一条指令是否能够被接收，直到所有的序列发出为止。

![img](./06-03-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1515111-20200618105837505-1346601754-1724940788956-87.png)

发出指令后，一般会有两种可能出现的情况。在大多数情况下，设备驱动程序会进行等待直到控制器完成它的事情。这里需要了解一下设备控制器的概念

> 设备控制器的主要主责是**控制一个或多个 I/O 设备，以实现 I/O 设备和计算机之间的数据交换**。
>
> 设备控制器接收从 CPU 发送过来的指令，继而达到控制硬件的目的

设备控制器是一个`可编址`的设备，当它仅控制一个设备时，它只有一个唯一的设备地址；如果设备控制器控制多个可连接设备时，则应含有多个设备地址，并使每一个设备地址对应一个设备。

设备控制器主要分为两种：字符设备和块设备

设备控制器的主要功能有下面这些

- 接收和识别命令：设备控制器可以接受来自 CPU 的指令，并进行识别。设备控制器内部也会有寄存器，用来存放指令和参数
- 进行数据交换：CPU、控制器和设备之间会进行数据的交换，CPU 通过总线把指令发送给控制器，或从控制器中并行地读出数据；控制器将数据写入指定设备。
- 地址识别：每个硬件设备都有自己的地址，设备控制器能够识别这些不同的地址，来达到控制硬件的目的，此外，为使 CPU 能向寄存器中写入或者读取数据，这些寄存器都应具有唯一的地址。
- 差错检测：设备控制器还具有对设备传递过来的数据进行检测的功能。

在这种情况下，设备控制器会阻塞，直到中断来解除阻塞状态。还有一种情况是操作是可以无延迟的完成，所以驱动程序不需要阻塞。在第一种情况下，操作系统可能被中断唤醒；第二种情况下操作系统不会被休眠。

设备驱动程序必须是`可重入`的，因为设备驱动程序会阻塞和唤醒然后再次阻塞。驱动程序不允许进行系统调用，但是它们通常需要与内核的其余部分进行交互。
